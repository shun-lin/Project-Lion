{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QA Jokes.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["CK3xqR3hM09r","S6_qnXS8Aygy"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"9KhsoeIFllYP","colab_type":"code","colab":{}},"cell_type":"code","source":["from __future__ import absolute_import, division, print_function\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import collections\n","import os\n","import string\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zsLhSubsllYY","colab_type":"code","outputId":"87d4e55e-5f63-41b2-b40f-e971e7db96b9","executionInfo":{"status":"ok","timestamp":1556764162668,"user_tz":420,"elapsed":1767,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import keras\n","import sklearn\n","import tensorflow as tf\n","\n","from keras import backend as K\n","from keras import layers\n","from keras.models import Model, Sequential\n","from keras.layers import Dense, Embedding, Input, Lambda, LSTM, Masking, RepeatVector, TimeDistributed\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"3J4TMcAOlsEE","colab_type":"code","outputId":"7645e717-216f-45bd-a949-93c986c592d0","executionInfo":{"status":"ok","timestamp":1556764190626,"user_tz":420,"elapsed":21300,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["# Getting access to the dataset and the Python files on Google Drive.\n","# You will probably have to give permission.\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","root_folder = \"/content/gdrive/My Drive/Project-Lion/\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"7d6LIw55llYg","colab_type":"code","colab":{}},"cell_type":"code","source":["df = pd.read_csv(root_folder + 'data/kaggle/shortjokes.csv')\n","df = df.loc[df[\"Joke\"] != \"\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yZiboxqYllYl","colab_type":"code","colab":{}},"cell_type":"code","source":["def clean_data(lst, in_place=True, keep_punc=\"\"):\n","    if in_place:\n","        new_lst = lst\n","    else:\n","        new_lst = lst.copy()\n","        \n","    for i in range(len(new_lst)):\n","        joke = lst[i]\n","        joke = joke.replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"/\", \" or \")\n","        joke = joke.translate(str.maketrans(\"\", \"\", string.punctuation.replace(keep_punc, \"\"))) # Remove punctuation\n","        joke = joke.lower() # Lowercase\n","        joke = ''.join(char for char in joke if not char.isdigit()) # Remove numbers\n","        joke = joke.strip() # Remove leading and ending whitespace\n","        new_lst[i] = joke\n","    return new_lst"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nhw_-r7hllYt","colab_type":"code","colab":{}},"cell_type":"code","source":["data = clean_data(df[\"Joke\"].tolist(), keep_punc=\"?\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wn5W5g9XllY8","colab_type":"text"},"cell_type":"markdown","source":["#### Filter by QA jokes\n","#### Only keep jokes with a question length > 24 and an answer length > 4 "]},{"metadata":{"id":"ef5TTgPCSVt5","colab_type":"code","outputId":"dc3c69bd-5e19-4b82-c4c6-0d050339bbe6","executionInfo":{"status":"ok","timestamp":1556764254309,"user_tz":420,"elapsed":784,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["qa_all = [[s.strip() for s in list(filter(None, joke.split(\"?\")))] for joke in data if len(list(filter(None, joke.split(\"?\")))) == 2]\n","print(qa_all[0])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["['why cant barbie get pregnant', 'because ken comes in a different box heyooooooo']\n"],"name":"stdout"}]},{"metadata":{"id":"1qo7fyVwmHR-","colab_type":"code","outputId":"152bcfaf-4c98-47ea-87ad-88c58b89a707","executionInfo":{"status":"ok","timestamp":1556764262240,"user_tz":420,"elapsed":271,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["cnt = {}\n","for q, a in qa_all:\n","  if len(a.split()) not in cnt:\n","    cnt[len(a.split())] = 0\n","  cnt[len(a.split())] += 1\n","max(cnt, key=lambda x: cnt[x])"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"BzGWttRHllY9","colab_type":"code","outputId":"2e6dc321-04c6-4149-cd67-9f987ef25f60","executionInfo":{"status":"ok","timestamp":1556764271994,"user_tz":420,"elapsed":285,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["qa = [(q, a) for q, a in qa_all if len(q) >= 15 and len(a.split()) > 3 and len(a.split()) < 30]\n","print(\"Size of dataset:\", len(qa))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Size of dataset: 60284\n"],"name":"stdout"}]},{"metadata":{"id":"3GngvUY8llZF","colab_type":"code","outputId":"ebdc9185-1bc0-498a-9682-b50ec87e8118","executionInfo":{"status":"ok","timestamp":1556764284629,"user_tz":420,"elapsed":1836,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":87}},"cell_type":"code","source":["combined_qa = [q + \" \" + \"starttok\" + \" \" + a for q, a in qa]\n","tokenizer = Tokenizer(num_words=20000, oov_token=\"unktok\")\n","tokenizer.fit_on_texts(combined_qa)\n","word2idx = tokenizer.word_index.copy()\n","idx2word = {key: value for value, key in word2idx.items()}\n","start_idx = word2idx['starttok']\n","unk_index = word2idx['unktok']\n","vocab_size = len(word2idx)\n","print(\"Vocab size:\", vocab_size)\n","print(start_idx)\n","print(unk_index)\n","len(combined_qa)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Vocab size: 34050\n","2\n","1\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["60284"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"YDGiVpMvllZM","colab_type":"code","outputId":"65eb2920-c951-46de-b611-81c4837a7fde","executionInfo":{"status":"ok","timestamp":1556764299024,"user_tz":420,"elapsed":2646,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["encoded = tokenizer.texts_to_sequences(combined_qa)\n","encoded_q, encoded_a = [], []\n","\n","for i in range(len(encoded)):\n","    e = encoded[i]\n","    q_len = len(qa[i][0].split())\n","    e_q = e[:q_len]\n","    e_a = e[q_len:]\n","    encoded_q.append(e_q)\n","    encoded_a.append(e_a)\n","\n","\n","encoded_q = keras.preprocessing.sequence.pad_sequences(encoded_q, padding=\"post\")\n","encoded_a = keras.preprocessing.sequence.pad_sequences(encoded_a, padding=\"post\")\n","input_steps = encoded_q.shape[1]\n","output_steps = encoded_a.shape[1] - 1\n","data_size = encoded_q.shape[0]\n","idx2word[0] = 'PAD'\n","\n","print(input_steps, output_steps, data_size)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["47 29 60284\n"],"name":"stdout"}]},{"metadata":{"id":"e1kcwWoxaKuk","colab_type":"code","outputId":"ff99b860-346b-4bbd-8efc-853ea87fcae6","executionInfo":{"status":"ok","timestamp":1556764303575,"user_tz":420,"elapsed":262,"user":{"displayName":"ALLEN CHEN","photoUrl":"","userId":"13117472557552131577"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# testing that encoding and decoding are the same\n","\n","idx2word[9910]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'deeds'"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"9oH6zqwMllZR","colab_type":"text"},"cell_type":"markdown","source":["# Create Model"]},{"metadata":{"id":"nxQe6GmvllZR","colab_type":"code","colab":{}},"cell_type":"code","source":["class KerasBatchGenerator(object):\n","\n","  def __init__(self, input_data, target_data, input_steps, output_steps, batch_size, vocab_size):\n","    self.input_data = input_data\n","    self.target_data = target_data\n","    self.input_steps = input_steps\n","    self.output_steps = output_steps\n","    self.batch_size = batch_size\n","    self.vocab_size = vocab_size\n","\n","  def generate(self):\n","    while True:\n","      idx = np.random.randint(self.input_data.shape[0] - batch_size - 1, size=batch_size)\n","\n","      encoder_input = np.array([self.input_data[i] for i in idx])\n","      targets = np.array([self.target_data[i] for i in idx])\n","      decoder_input = targets[:, :-1]\n","      decoder_output = targets[:, 1:]\n","      \n","      #mask = np.expand_dims(decoder_output != 0, axis=2)\n","      #mask = decoder_output != 0\n","      decoder_output = tf.keras.utils.to_categorical(decoder_output, num_classes=self.vocab_size)\n","      #decoder_output = decoder_output.reshape(self.batch_size, self.output_steps, self.vocab_size)\n","      #decoder_output = decoder_output * mask\n","      \n","      yield [encoder_input, decoder_input], decoder_output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y5cmPVAnn1iM","colab_type":"code","outputId":"14e8e1a8-8479-4dad-f258-38ea157fb869","executionInfo":{"status":"ok","timestamp":1555709044817,"user_tz":420,"elapsed":1347,"user":{"displayName":"SHUN LIN","photoUrl":"https://lh4.googleusercontent.com/-pkp40ccE7So/AAAAAAAAAAI/AAAAAAAAAU4/Upp1QcV6fHs/s64/photo.jpg","userId":"16137932526864003348"}},"colab":{"base_uri":"https://localhost:8080/","height":547}},"cell_type":"code","source":["K.clear_session()\n","\n","embed_dim = 128\n","latent_dim = 128\n","\n","encoder_inputs = Input(shape=(input_steps,))\n","decoder_inputs = Input(shape=(output_steps,))\n","\n","# add on\n","# encoder_masked = Masking(mask_value=0)(encoder_inputs)\n","\n","# masked = Masking(mask_value=0)(decoder_inputs)\n","\n","\n","\n","embedding = Embedding(vocab_size, embed_dim, mask_zero=True)\n","embedding2 = Embedding(vocab_size, embed_dim, mask_zero=True)\n","\n","# enc_embed = embedding(encoder_masked)\n","enc_embed = embedding(encoder_inputs)\n","# dec_embed = embedding(masked)\n","dec_embed = embedding2(decoder_inputs)\n","\n","encoder_LSTM = LSTM(latent_dim, dropout=0.2, recurrent_dropout=0.2, return_state=True)\n","_, encoder_h, encoder_c = encoder_LSTM(enc_embed)\n","\n","decoder_LSTM = LSTM(latent_dim, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)\n","decoder_outputs = decoder_LSTM(dec_embed, initial_state=[encoder_h, encoder_c])\n","\n","\n","time_distr = TimeDistributed(Dense(vocab_size, activation='softmax'))\n","outputs = time_distr(decoder_outputs)\n","#decoder_dense = Dense(vocab_size, activation='softmax')\n","#outputs = decoder_dense(decoder_outputs)\n","\n","model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n","model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy'])\n","print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 47)           0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 29)           0                                            \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, 47, 128)      4358400     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, 29, 128)      4358400     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 128), (None, 131584      embedding_1[0][0]                \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   (None, 29, 128)      131584      embedding_2[0][0]                \n","                                                                 lstm_1[0][1]                     \n","                                                                 lstm_1[0][2]                     \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 29, 34050)    4392450     lstm_2[0][0]                     \n","==================================================================================================\n","Total params: 13,372,418\n","Trainable params: 13,372,418\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"I0d7w5WYM8ix","colab_type":"code","colab":{}},"cell_type":"code","source":["batch_size = 64\n","num_epochs = 10\n","train_size = data_size * 4 // 5\n","train_steps_per_epoch = 100 # train_size // batch_size\n","valid_steps_per_epoch = 10 \n","\n","train_q, train_a = encoded_q[:train_size], encoded_a[:train_size]\n","valid_q, valid_a = encoded_q[train_size:], encoded_a[train_size:]\n","\n","#train_q, train_a = encoded_q[:10 * 32], encoded_a[:10 * 32]\n","#valid_q, valid_a = encoded_q[10 * 32:], encoded_a[10 * 32:]\n","\n","train_data_generator = KerasBatchGenerator(train_q, train_a, input_steps, output_steps, batch_size, vocab_size)\n","valid_data_generator = KerasBatchGenerator(valid_q, valid_a, input_steps, output_steps, batch_size, vocab_size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"37ZX6dMfhvtd","colab_type":"code","colab":{}},"cell_type":"code","source":["# unit test for KerasBatchGenerator\n","batches = train_data_generator.generate()\n","one_batch = None\n","for batch in batches:\n","  one_batch = batch\n","  break"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mQ4H4IHmi9rf","colab_type":"code","colab":{}},"cell_type":"code","source":["# model.load_weights(root_folder + 'models/keras_model.h5')\n","plot_info_path = root_folder+\"plots/keras_model_history.csv\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"HBd-SzHJM9T3","colab_type":"code","outputId":"4f0e185d-f0d2-4819-a5dd-4a629d0d8493","executionInfo":{"status":"error","timestamp":1554564584738,"user_tz":420,"elapsed":28065142,"user":{"displayName":"SHUN LIN","photoUrl":"https://lh4.googleusercontent.com/-pkp40ccE7So/AAAAAAAAAAI/AAAAAAAAAU4/Upp1QcV6fHs/s64/photo.jpg","userId":"16137932526864003348"}},"colab":{"base_uri":"https://localhost:8080/","height":24245}},"cell_type":"code","source":["plot_info = pd.DataFrame(columns=['training_err', 'validation_err', 'training_acc', 'validation_acc'])\n","\n","while True:\n","  history = model.fit_generator(train_data_generator.generate(), train_steps_per_epoch, epochs=num_epochs,\n","                          validation_data=valid_data_generator.generate(), validation_steps=valid_steps_per_epoch)\n","  print(\"saving model weights ....\")\n","  model.save(root_folder + 'models/keras_model_2.h5')\n","  print(\"saving model weights completed....\")\n","  print(\"saving plot info ....\")\n","  training_acc = history.history['acc']\n","  validation_acc = history.history['val_acc']\n","  training_loss = history.history['loss']\n","  validation_loss = history.history['val_loss']\n","  rows = np.array([training_loss, validation_loss, training_acc, validation_acc]).T\n","  df_temp = pd.DataFrame(rows, columns=plot_info.columns)\n","  plot_info = plot_info.append(df_temp, ignore_index=True)\n","  plot_info.to_csv(plot_info_path, index=False)\n","  print(\"saving plot info completed ....\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","100/100 [==============================] - 55s 550ms/step - loss: 6.2729 - acc: 0.1315 - val_loss: 6.2503 - val_acc: 0.1382\n","Epoch 2/10\n","100/100 [==============================] - 54s 540ms/step - loss: 6.2291 - acc: 0.1324 - val_loss: 6.2105 - val_acc: 0.1366\n","Epoch 3/10\n","100/100 [==============================] - 53s 530ms/step - loss: 6.1833 - acc: 0.1344 - val_loss: 6.1935 - val_acc: 0.1406\n","Epoch 4/10\n","100/100 [==============================] - 53s 531ms/step - loss: 6.1385 - acc: 0.1376 - val_loss: 6.2364 - val_acc: 0.1408\n","Epoch 5/10\n","100/100 [==============================] - 53s 531ms/step - loss: 6.1248 - acc: 0.1402 - val_loss: 6.1039 - val_acc: 0.1378\n","Epoch 6/10\n","100/100 [==============================] - 53s 532ms/step - loss: 6.0628 - acc: 0.1478 - val_loss: 6.1913 - val_acc: 0.1430\n","Epoch 7/10\n","100/100 [==============================] - 53s 527ms/step - loss: 6.0517 - acc: 0.1526 - val_loss: 6.1219 - val_acc: 0.1503\n","Epoch 8/10\n","100/100 [==============================] - 53s 527ms/step - loss: 6.0290 - acc: 0.1544 - val_loss: 6.1167 - val_acc: 0.1536\n","Epoch 9/10\n","100/100 [==============================] - 53s 532ms/step - loss: 5.9987 - acc: 0.1555 - val_loss: 6.0473 - val_acc: 0.1602\n","Epoch 10/10\n","100/100 [==============================] - 53s 529ms/step - loss: 5.9753 - acc: 0.1570 - val_loss: 5.9882 - val_acc: 0.1594\n","saving model weights ....\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_4:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 538ms/step - loss: 5.9447 - acc: 0.1598 - val_loss: 5.9376 - val_acc: 0.1594\n","Epoch 2/10\n","100/100 [==============================] - 53s 528ms/step - loss: 5.8833 - acc: 0.1622 - val_loss: 5.9543 - val_acc: 0.1524\n","Epoch 3/10\n","100/100 [==============================] - 53s 532ms/step - loss: 5.8271 - acc: 0.1657 - val_loss: 5.9377 - val_acc: 0.1598\n","Epoch 4/10\n","100/100 [==============================] - 53s 530ms/step - loss: 5.8062 - acc: 0.1717 - val_loss: 5.7672 - val_acc: 0.1744\n","Epoch 5/10\n","100/100 [==============================] - 53s 527ms/step - loss: 5.6950 - acc: 0.1777 - val_loss: 5.6890 - val_acc: 0.1803\n","Epoch 6/10\n","100/100 [==============================] - 52s 520ms/step - loss: 5.6139 - acc: 0.1837 - val_loss: 5.6675 - val_acc: 0.1744\n","Epoch 7/10\n","100/100 [==============================] - 52s 518ms/step - loss: 5.5399 - acc: 0.1899 - val_loss: 5.5633 - val_acc: 0.1924\n","Epoch 8/10\n","100/100 [==============================] - 56s 555ms/step - loss: 5.4882 - acc: 0.1938 - val_loss: 5.4685 - val_acc: 0.1984\n","Epoch 9/10\n","100/100 [==============================] - 54s 538ms/step - loss: 5.4517 - acc: 0.1975 - val_loss: 5.5103 - val_acc: 0.1988\n","Epoch 10/10\n","100/100 [==============================] - 54s 538ms/step - loss: 5.4002 - acc: 0.2009 - val_loss: 5.4368 - val_acc: 0.1983\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 55s 549ms/step - loss: 5.3691 - acc: 0.2016 - val_loss: 5.4788 - val_acc: 0.2006\n","Epoch 2/10\n","100/100 [==============================] - 53s 534ms/step - loss: 5.2896 - acc: 0.2123 - val_loss: 5.2969 - val_acc: 0.2062\n","Epoch 3/10\n","100/100 [==============================] - 56s 556ms/step - loss: 5.2755 - acc: 0.2103 - val_loss: 5.3572 - val_acc: 0.2032\n","Epoch 4/10\n","100/100 [==============================] - 54s 542ms/step - loss: 5.2319 - acc: 0.2176 - val_loss: 5.2745 - val_acc: 0.2149\n","Epoch 5/10\n","100/100 [==============================] - 54s 538ms/step - loss: 5.1766 - acc: 0.2201 - val_loss: 5.3075 - val_acc: 0.2102\n","Epoch 6/10\n","100/100 [==============================] - 53s 532ms/step - loss: 5.1160 - acc: 0.2230 - val_loss: 5.2354 - val_acc: 0.2162\n","Epoch 7/10\n","100/100 [==============================] - 53s 534ms/step - loss: 5.0728 - acc: 0.2255 - val_loss: 5.2744 - val_acc: 0.2225\n","Epoch 8/10\n","100/100 [==============================] - 53s 525ms/step - loss: 5.0406 - acc: 0.2292 - val_loss: 5.1997 - val_acc: 0.2174\n","Epoch 9/10\n","100/100 [==============================] - 53s 531ms/step - loss: 5.0195 - acc: 0.2322 - val_loss: 5.3076 - val_acc: 0.2106\n","Epoch 10/10\n","100/100 [==============================] - 53s 528ms/step - loss: 4.9793 - acc: 0.2341 - val_loss: 5.1792 - val_acc: 0.2292\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 541ms/step - loss: 4.9649 - acc: 0.2343 - val_loss: 5.1981 - val_acc: 0.2247\n","Epoch 2/10\n","100/100 [==============================] - 53s 529ms/step - loss: 4.9235 - acc: 0.2356 - val_loss: 5.1327 - val_acc: 0.2267\n","Epoch 3/10\n","100/100 [==============================] - 51s 513ms/step - loss: 4.8780 - acc: 0.2425 - val_loss: 5.1037 - val_acc: 0.2343\n","Epoch 4/10\n","100/100 [==============================] - 51s 509ms/step - loss: 4.8481 - acc: 0.2435 - val_loss: 5.0688 - val_acc: 0.2395\n","Epoch 5/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.8325 - acc: 0.2458 - val_loss: 5.0857 - val_acc: 0.2349\n","Epoch 6/10\n","100/100 [==============================] - 51s 510ms/step - loss: 4.7970 - acc: 0.2498 - val_loss: 5.1236 - val_acc: 0.2353\n","Epoch 7/10\n","100/100 [==============================] - 51s 508ms/step - loss: 4.7692 - acc: 0.2506 - val_loss: 5.0097 - val_acc: 0.2398\n","Epoch 8/10\n","100/100 [==============================] - 51s 510ms/step - loss: 4.7469 - acc: 0.2534 - val_loss: 5.1405 - val_acc: 0.2344\n","Epoch 9/10\n","100/100 [==============================] - 51s 508ms/step - loss: 4.7045 - acc: 0.2554 - val_loss: 4.9317 - val_acc: 0.2380\n","Epoch 10/10\n","100/100 [==============================] - 51s 507ms/step - loss: 4.6690 - acc: 0.2624 - val_loss: 4.9260 - val_acc: 0.2511\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 518ms/step - loss: 4.6559 - acc: 0.2616 - val_loss: 5.0366 - val_acc: 0.2325\n","Epoch 2/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.6258 - acc: 0.2640 - val_loss: 4.9889 - val_acc: 0.2462\n","Epoch 3/10\n","100/100 [==============================] - 51s 508ms/step - loss: 4.5831 - acc: 0.2666 - val_loss: 4.9252 - val_acc: 0.2472\n","Epoch 4/10\n","100/100 [==============================] - 51s 509ms/step - loss: 4.5632 - acc: 0.2716 - val_loss: 4.8668 - val_acc: 0.2567\n","Epoch 5/10\n","100/100 [==============================] - 51s 508ms/step - loss: 4.5763 - acc: 0.2678 - val_loss: 4.9291 - val_acc: 0.2489\n","Epoch 6/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.5554 - acc: 0.2692 - val_loss: 4.7422 - val_acc: 0.2693\n","Epoch 7/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.4686 - acc: 0.2804 - val_loss: 4.9322 - val_acc: 0.2475\n","Epoch 8/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.4758 - acc: 0.2788 - val_loss: 4.9245 - val_acc: 0.2525\n","Epoch 9/10\n","100/100 [==============================] - 51s 505ms/step - loss: 4.4504 - acc: 0.2809 - val_loss: 4.7602 - val_acc: 0.2669\n","Epoch 10/10\n","100/100 [==============================] - 51s 511ms/step - loss: 4.4286 - acc: 0.2842 - val_loss: 4.8999 - val_acc: 0.2622\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 519ms/step - loss: 4.4058 - acc: 0.2841 - val_loss: 4.7262 - val_acc: 0.2699\n","Epoch 2/10\n","100/100 [==============================] - 50s 504ms/step - loss: 4.3790 - acc: 0.2880 - val_loss: 4.8537 - val_acc: 0.2579\n","Epoch 3/10\n","100/100 [==============================] - 50s 504ms/step - loss: 4.3608 - acc: 0.2904 - val_loss: 4.8088 - val_acc: 0.2662\n","Epoch 4/10\n","100/100 [==============================] - 50s 504ms/step - loss: 4.3227 - acc: 0.2949 - val_loss: 4.8582 - val_acc: 0.2659\n","Epoch 5/10\n","100/100 [==============================] - 50s 504ms/step - loss: 4.3204 - acc: 0.2977 - val_loss: 4.8224 - val_acc: 0.2703\n","Epoch 6/10\n","100/100 [==============================] - 51s 507ms/step - loss: 4.2828 - acc: 0.3009 - val_loss: 4.7493 - val_acc: 0.2656\n","Epoch 7/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.2756 - acc: 0.2986 - val_loss: 4.6073 - val_acc: 0.2870\n","Epoch 8/10\n","100/100 [==============================] - 50s 503ms/step - loss: 4.2274 - acc: 0.3050 - val_loss: 4.8107 - val_acc: 0.2566\n","Epoch 9/10\n","100/100 [==============================] - 50s 505ms/step - loss: 4.2300 - acc: 0.3025 - val_loss: 4.8269 - val_acc: 0.2628\n","Epoch 10/10\n","100/100 [==============================] - 52s 522ms/step - loss: 4.2339 - acc: 0.3046 - val_loss: 4.8455 - val_acc: 0.2645\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 518ms/step - loss: 4.2253 - acc: 0.3061 - val_loss: 4.7256 - val_acc: 0.2764\n","Epoch 2/10\n","100/100 [==============================] - 51s 510ms/step - loss: 4.1976 - acc: 0.3078 - val_loss: 4.7777 - val_acc: 0.2778\n","Epoch 3/10\n","100/100 [==============================] - 51s 509ms/step - loss: 4.1699 - acc: 0.3098 - val_loss: 4.7156 - val_acc: 0.2772\n","Epoch 4/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.1389 - acc: 0.3121 - val_loss: 4.6457 - val_acc: 0.2866\n","Epoch 5/10\n","100/100 [==============================] - 50s 504ms/step - loss: 4.1353 - acc: 0.3112 - val_loss: 4.8948 - val_acc: 0.2641\n","Epoch 6/10\n","100/100 [==============================] - 51s 506ms/step - loss: 4.1097 - acc: 0.3169 - val_loss: 4.7862 - val_acc: 0.2734\n","Epoch 7/10\n","100/100 [==============================] - 50s 504ms/step - loss: 4.1230 - acc: 0.3146 - val_loss: 4.8145 - val_acc: 0.2627\n","Epoch 8/10\n","100/100 [==============================] - 50s 505ms/step - loss: 4.0717 - acc: 0.3179 - val_loss: 4.7102 - val_acc: 0.2960\n","Epoch 9/10\n","100/100 [==============================] - 51s 511ms/step - loss: 4.0380 - acc: 0.3212 - val_loss: 4.5987 - val_acc: 0.3003\n","Epoch 10/10\n","100/100 [==============================] - 50s 505ms/step - loss: 4.0469 - acc: 0.3236 - val_loss: 4.6317 - val_acc: 0.2906\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 519ms/step - loss: 4.0349 - acc: 0.3220 - val_loss: 4.6073 - val_acc: 0.2904\n","Epoch 2/10\n","100/100 [==============================] - 50s 504ms/step - loss: 3.9975 - acc: 0.3297 - val_loss: 4.6853 - val_acc: 0.2805\n","Epoch 3/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.9633 - acc: 0.3300 - val_loss: 4.5907 - val_acc: 0.2932\n","Epoch 4/10\n","100/100 [==============================] - 50s 504ms/step - loss: 3.9590 - acc: 0.3309 - val_loss: 4.8423 - val_acc: 0.2691\n","Epoch 5/10\n","100/100 [==============================] - 51s 511ms/step - loss: 3.9670 - acc: 0.3292 - val_loss: 4.6860 - val_acc: 0.2824\n","Epoch 6/10\n","100/100 [==============================] - 51s 508ms/step - loss: 3.9580 - acc: 0.3330 - val_loss: 4.6723 - val_acc: 0.2857\n","Epoch 7/10\n","100/100 [==============================] - 50s 505ms/step - loss: 3.9519 - acc: 0.3353 - val_loss: 4.6780 - val_acc: 0.2862\n","Epoch 8/10\n","100/100 [==============================] - 51s 510ms/step - loss: 3.9038 - acc: 0.3358 - val_loss: 4.7561 - val_acc: 0.2800\n","Epoch 9/10\n","100/100 [==============================] - 51s 506ms/step - loss: 3.8946 - acc: 0.3404 - val_loss: 4.6638 - val_acc: 0.2840\n","Epoch 10/10\n","100/100 [==============================] - 51s 508ms/step - loss: 3.8749 - acc: 0.3379 - val_loss: 4.7447 - val_acc: 0.2863\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 523ms/step - loss: 3.8817 - acc: 0.3391 - val_loss: 4.6702 - val_acc: 0.2904\n","Epoch 2/10\n","100/100 [==============================] - 51s 506ms/step - loss: 3.8568 - acc: 0.3406 - val_loss: 4.6722 - val_acc: 0.2854\n","Epoch 3/10\n","100/100 [==============================] - 51s 507ms/step - loss: 3.8264 - acc: 0.3453 - val_loss: 4.5911 - val_acc: 0.2939\n","Epoch 4/10\n","100/100 [==============================] - 51s 505ms/step - loss: 3.8222 - acc: 0.3461 - val_loss: 4.6718 - val_acc: 0.2915\n","Epoch 5/10\n","100/100 [==============================] - 51s 506ms/step - loss: 3.7886 - acc: 0.3494 - val_loss: 4.6990 - val_acc: 0.2956\n","Epoch 6/10\n","100/100 [==============================] - 50s 502ms/step - loss: 3.7832 - acc: 0.3496 - val_loss: 4.6388 - val_acc: 0.2944\n","Epoch 7/10\n","100/100 [==============================] - 51s 509ms/step - loss: 3.7889 - acc: 0.3487 - val_loss: 4.5323 - val_acc: 0.3104\n","Epoch 8/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.7719 - acc: 0.3517 - val_loss: 4.6243 - val_acc: 0.3024\n","Epoch 9/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.7412 - acc: 0.3564 - val_loss: 4.7336 - val_acc: 0.2803\n","Epoch 10/10\n","100/100 [==============================] - 51s 505ms/step - loss: 3.7614 - acc: 0.3550 - val_loss: 4.6089 - val_acc: 0.2957\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 51s 513ms/step - loss: 3.7536 - acc: 0.3568 - val_loss: 4.6418 - val_acc: 0.3065\n","Epoch 2/10\n","100/100 [==============================] - 50s 504ms/step - loss: 3.6963 - acc: 0.3584 - val_loss: 4.6772 - val_acc: 0.2814\n","Epoch 3/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.6866 - acc: 0.3616 - val_loss: 4.6663 - val_acc: 0.2879\n","Epoch 4/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.6690 - acc: 0.3622 - val_loss: 4.5649 - val_acc: 0.3004\n","Epoch 5/10\n","100/100 [==============================] - 50s 500ms/step - loss: 3.6711 - acc: 0.3624 - val_loss: 4.4978 - val_acc: 0.3087\n","Epoch 6/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.6401 - acc: 0.3642 - val_loss: 4.7031 - val_acc: 0.2944\n","Epoch 7/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.6723 - acc: 0.3629 - val_loss: 4.6117 - val_acc: 0.2964\n","Epoch 8/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.6249 - acc: 0.3656 - val_loss: 4.5640 - val_acc: 0.3086\n","Epoch 9/10\n","100/100 [==============================] - 50s 505ms/step - loss: 3.6258 - acc: 0.3683 - val_loss: 4.6092 - val_acc: 0.3022\n","Epoch 10/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.6034 - acc: 0.3707 - val_loss: 4.5805 - val_acc: 0.3074\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 51s 513ms/step - loss: 3.6130 - acc: 0.3687 - val_loss: 4.6172 - val_acc: 0.3013\n","Epoch 2/10\n","100/100 [==============================] - 50s 504ms/step - loss: 3.5721 - acc: 0.3731 - val_loss: 4.7304 - val_acc: 0.2883\n","Epoch 3/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.6043 - acc: 0.3690 - val_loss: 4.7542 - val_acc: 0.3039\n","Epoch 4/10\n","100/100 [==============================] - 50s 502ms/step - loss: 3.5473 - acc: 0.3754 - val_loss: 4.6040 - val_acc: 0.3134\n","Epoch 5/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.5461 - acc: 0.3776 - val_loss: 4.5382 - val_acc: 0.3109\n","Epoch 6/10\n","100/100 [==============================] - 50s 498ms/step - loss: 3.5024 - acc: 0.3805 - val_loss: 4.6040 - val_acc: 0.3092\n","Epoch 7/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.4979 - acc: 0.3838 - val_loss: 4.6422 - val_acc: 0.2947\n","Epoch 8/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.5214 - acc: 0.3764 - val_loss: 4.6827 - val_acc: 0.3026\n","Epoch 9/10\n","100/100 [==============================] - 50s 498ms/step - loss: 3.5029 - acc: 0.3819 - val_loss: 4.7172 - val_acc: 0.3099\n","Epoch 10/10\n","100/100 [==============================] - 50s 496ms/step - loss: 3.5166 - acc: 0.3802 - val_loss: 4.7022 - val_acc: 0.3022\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 51s 511ms/step - loss: 3.4491 - acc: 0.3908 - val_loss: 4.6083 - val_acc: 0.3027\n","Epoch 2/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.4883 - acc: 0.3859 - val_loss: 4.7002 - val_acc: 0.2998\n","Epoch 3/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.4598 - acc: 0.3866 - val_loss: 4.4687 - val_acc: 0.3233\n","Epoch 4/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.4530 - acc: 0.3874 - val_loss: 4.4997 - val_acc: 0.3171\n","Epoch 5/10\n","100/100 [==============================] - 50s 496ms/step - loss: 3.4430 - acc: 0.3875 - val_loss: 4.5719 - val_acc: 0.3294\n","Epoch 6/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.4301 - acc: 0.3921 - val_loss: 4.5517 - val_acc: 0.3085\n","Epoch 7/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.4045 - acc: 0.3924 - val_loss: 4.6283 - val_acc: 0.3066\n","Epoch 8/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.4120 - acc: 0.3918 - val_loss: 4.7677 - val_acc: 0.2977\n","Epoch 9/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.3750 - acc: 0.3982 - val_loss: 4.5545 - val_acc: 0.3072\n","Epoch 10/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.3628 - acc: 0.3938 - val_loss: 4.6752 - val_acc: 0.3039\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 51s 511ms/step - loss: 3.3390 - acc: 0.4022 - val_loss: 4.6084 - val_acc: 0.3109\n","Epoch 2/10\n","100/100 [==============================] - 50s 499ms/step - loss: 3.3566 - acc: 0.3996 - val_loss: 4.6129 - val_acc: 0.3187\n","Epoch 3/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.3722 - acc: 0.3959 - val_loss: 4.5678 - val_acc: 0.3082\n","Epoch 4/10\n","100/100 [==============================] - 50s 498ms/step - loss: 3.3476 - acc: 0.3994 - val_loss: 4.6251 - val_acc: 0.3113\n","Epoch 5/10\n","100/100 [==============================] - 49s 494ms/step - loss: 3.3165 - acc: 0.4023 - val_loss: 4.5957 - val_acc: 0.3124\n","Epoch 6/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.3032 - acc: 0.4069 - val_loss: 4.7122 - val_acc: 0.2984\n","Epoch 7/10\n","100/100 [==============================] - 50s 495ms/step - loss: 3.3540 - acc: 0.3996 - val_loss: 4.5553 - val_acc: 0.3239\n","Epoch 8/10\n","100/100 [==============================] - 50s 498ms/step - loss: 3.3215 - acc: 0.4043 - val_loss: 4.4625 - val_acc: 0.3387\n","Epoch 9/10\n","100/100 [==============================] - 50s 496ms/step - loss: 3.2867 - acc: 0.4081 - val_loss: 4.5209 - val_acc: 0.3218\n","Epoch 10/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.2623 - acc: 0.4092 - val_loss: 4.8708 - val_acc: 0.2893\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 51s 507ms/step - loss: 3.2903 - acc: 0.4053 - val_loss: 4.5226 - val_acc: 0.3214\n","Epoch 2/10\n","100/100 [==============================] - 50s 496ms/step - loss: 3.2788 - acc: 0.4071 - val_loss: 4.7236 - val_acc: 0.3058\n","Epoch 3/10\n","100/100 [==============================] - 50s 496ms/step - loss: 3.2332 - acc: 0.4130 - val_loss: 4.5021 - val_acc: 0.3242\n","Epoch 4/10\n","100/100 [==============================] - 49s 492ms/step - loss: 3.2122 - acc: 0.4184 - val_loss: 4.5489 - val_acc: 0.3231\n","Epoch 5/10\n","100/100 [==============================] - 49s 495ms/step - loss: 3.1882 - acc: 0.4199 - val_loss: 4.5655 - val_acc: 0.3282\n","Epoch 6/10\n","100/100 [==============================] - 49s 494ms/step - loss: 3.2170 - acc: 0.4154 - val_loss: 4.8467 - val_acc: 0.2972\n","Epoch 7/10\n","100/100 [==============================] - 49s 491ms/step - loss: 3.1804 - acc: 0.4203 - val_loss: 4.5932 - val_acc: 0.3204\n","Epoch 8/10\n","100/100 [==============================] - 49s 493ms/step - loss: 3.1892 - acc: 0.4178 - val_loss: 4.6511 - val_acc: 0.3180\n","Epoch 9/10\n","100/100 [==============================] - 49s 495ms/step - loss: 3.1995 - acc: 0.4181 - val_loss: 4.6454 - val_acc: 0.3215\n","Epoch 10/10\n","100/100 [==============================] - 50s 497ms/step - loss: 3.1651 - acc: 0.4243 - val_loss: 4.6372 - val_acc: 0.3114\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 517ms/step - loss: 3.1709 - acc: 0.4248 - val_loss: 4.5134 - val_acc: 0.3237\n","Epoch 2/10\n","100/100 [==============================] - 51s 509ms/step - loss: 3.1653 - acc: 0.4255 - val_loss: 4.6579 - val_acc: 0.3088\n","Epoch 3/10\n","100/100 [==============================] - 50s 504ms/step - loss: 3.1681 - acc: 0.4221 - val_loss: 4.7701 - val_acc: 0.3003\n","Epoch 4/10\n","100/100 [==============================] - 50s 502ms/step - loss: 3.1407 - acc: 0.4263 - val_loss: 4.7348 - val_acc: 0.3041\n","Epoch 5/10\n","100/100 [==============================] - 50s 502ms/step - loss: 3.1145 - acc: 0.4307 - val_loss: 4.6610 - val_acc: 0.3101\n","Epoch 6/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.1021 - acc: 0.4337 - val_loss: 4.8272 - val_acc: 0.2954\n","Epoch 7/10\n","100/100 [==============================] - 51s 512ms/step - loss: 3.0978 - acc: 0.4308 - val_loss: 4.6381 - val_acc: 0.3246\n","Epoch 8/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.0916 - acc: 0.4331 - val_loss: 4.6499 - val_acc: 0.3165\n","Epoch 9/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.1314 - acc: 0.4285 - val_loss: 4.5856 - val_acc: 0.3211\n","Epoch 10/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.0771 - acc: 0.4318 - val_loss: 4.7744 - val_acc: 0.3084\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 518ms/step - loss: 3.0883 - acc: 0.4314 - val_loss: 4.5607 - val_acc: 0.3309\n","Epoch 2/10\n","100/100 [==============================] - 52s 517ms/step - loss: 3.0820 - acc: 0.4325 - val_loss: 4.7623 - val_acc: 0.3026\n","Epoch 3/10\n","100/100 [==============================] - 50s 501ms/step - loss: 3.0829 - acc: 0.4326 - val_loss: 4.7747 - val_acc: 0.2974\n","Epoch 4/10\n","100/100 [==============================] - 51s 506ms/step - loss: 3.0423 - acc: 0.4370 - val_loss: 4.7200 - val_acc: 0.3122\n","Epoch 5/10\n","100/100 [==============================] - 51s 507ms/step - loss: 3.0628 - acc: 0.4340 - val_loss: 4.6702 - val_acc: 0.3157\n","Epoch 6/10\n","100/100 [==============================] - 50s 502ms/step - loss: 3.0321 - acc: 0.4413 - val_loss: 4.7614 - val_acc: 0.3079\n","Epoch 7/10\n","100/100 [==============================] - 50s 505ms/step - loss: 3.0234 - acc: 0.4425 - val_loss: 4.6127 - val_acc: 0.3165\n","Epoch 8/10\n","100/100 [==============================] - 50s 502ms/step - loss: 3.0290 - acc: 0.4406 - val_loss: 4.6149 - val_acc: 0.3163\n","Epoch 9/10\n","100/100 [==============================] - 51s 507ms/step - loss: 3.0234 - acc: 0.4396 - val_loss: 4.6355 - val_acc: 0.3122\n","Epoch 10/10\n","100/100 [==============================] - 50s 503ms/step - loss: 3.0265 - acc: 0.4422 - val_loss: 4.7952 - val_acc: 0.3090\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 525ms/step - loss: 3.0304 - acc: 0.4406 - val_loss: 4.6090 - val_acc: 0.3211\n","Epoch 2/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.9797 - acc: 0.4465 - val_loss: 4.6780 - val_acc: 0.3189\n","Epoch 3/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.9659 - acc: 0.4500 - val_loss: 4.7454 - val_acc: 0.3047\n","Epoch 4/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.9417 - acc: 0.4515 - val_loss: 4.6031 - val_acc: 0.3267\n","Epoch 5/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.9961 - acc: 0.4454 - val_loss: 4.7138 - val_acc: 0.3097\n","Epoch 6/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.9611 - acc: 0.4512 - val_loss: 4.6329 - val_acc: 0.3228\n","Epoch 7/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.9729 - acc: 0.4470 - val_loss: 4.8075 - val_acc: 0.3060\n","Epoch 8/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.9449 - acc: 0.4515 - val_loss: 4.7883 - val_acc: 0.3086\n","Epoch 9/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.9337 - acc: 0.4514 - val_loss: 4.7422 - val_acc: 0.3126\n","Epoch 10/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.9237 - acc: 0.4569 - val_loss: 4.7909 - val_acc: 0.3158\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.9360 - acc: 0.4571 - val_loss: 4.5117 - val_acc: 0.3398\n","Epoch 2/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.9402 - acc: 0.4534 - val_loss: 4.5197 - val_acc: 0.3335\n","Epoch 3/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.8955 - acc: 0.4600 - val_loss: 4.6139 - val_acc: 0.3253\n","Epoch 4/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.9101 - acc: 0.4569 - val_loss: 4.6994 - val_acc: 0.3169\n","Epoch 5/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.9174 - acc: 0.4522 - val_loss: 4.8529 - val_acc: 0.3020\n","Epoch 6/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.9153 - acc: 0.4581 - val_loss: 4.7391 - val_acc: 0.3146\n","Epoch 7/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.9004 - acc: 0.4576 - val_loss: 4.5857 - val_acc: 0.3397\n","Epoch 8/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.8855 - acc: 0.4605 - val_loss: 4.6907 - val_acc: 0.3281\n","Epoch 9/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.8452 - acc: 0.4644 - val_loss: 4.6884 - val_acc: 0.3182\n","Epoch 10/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.8319 - acc: 0.4683 - val_loss: 4.5748 - val_acc: 0.3278\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 529ms/step - loss: 2.8574 - acc: 0.4640 - val_loss: 4.7789 - val_acc: 0.3116\n","Epoch 2/10\n","100/100 [==============================] - 56s 555ms/step - loss: 2.8373 - acc: 0.4686 - val_loss: 4.6251 - val_acc: 0.3155\n","Epoch 3/10\n","100/100 [==============================] - 53s 527ms/step - loss: 2.8792 - acc: 0.4597 - val_loss: 4.6882 - val_acc: 0.3194\n","Epoch 4/10\n","100/100 [==============================] - 52s 524ms/step - loss: 2.8797 - acc: 0.4634 - val_loss: 4.6557 - val_acc: 0.3207\n","Epoch 5/10\n","100/100 [==============================] - 53s 531ms/step - loss: 2.8533 - acc: 0.4650 - val_loss: 4.5630 - val_acc: 0.3372\n","Epoch 6/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.8005 - acc: 0.4737 - val_loss: 4.5430 - val_acc: 0.3414\n","Epoch 7/10\n","100/100 [==============================] - 53s 529ms/step - loss: 2.8307 - acc: 0.4680 - val_loss: 4.7196 - val_acc: 0.3211\n","Epoch 8/10\n","100/100 [==============================] - 53s 527ms/step - loss: 2.8083 - acc: 0.4720 - val_loss: 4.5146 - val_acc: 0.3309\n","Epoch 9/10\n","100/100 [==============================] - 53s 528ms/step - loss: 2.7989 - acc: 0.4710 - val_loss: 4.6915 - val_acc: 0.3246\n","Epoch 10/10\n","100/100 [==============================] - 53s 526ms/step - loss: 2.7861 - acc: 0.4745 - val_loss: 4.7694 - val_acc: 0.3177\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 536ms/step - loss: 2.7696 - acc: 0.4773 - val_loss: 4.5946 - val_acc: 0.3315\n","Epoch 2/10\n","100/100 [==============================] - 52s 524ms/step - loss: 2.7902 - acc: 0.4761 - val_loss: 4.6598 - val_acc: 0.3316\n","Epoch 3/10\n","100/100 [==============================] - 52s 523ms/step - loss: 2.7540 - acc: 0.4778 - val_loss: 4.5458 - val_acc: 0.3278\n","Epoch 4/10\n","100/100 [==============================] - 53s 525ms/step - loss: 2.7510 - acc: 0.4780 - val_loss: 4.7406 - val_acc: 0.3232\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.7979 - acc: 0.4725 - val_loss: 4.6629 - val_acc: 0.3230\n","Epoch 6/10\n","100/100 [==============================] - 52s 523ms/step - loss: 2.7456 - acc: 0.4816 - val_loss: 4.5497 - val_acc: 0.3431\n","Epoch 7/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.7497 - acc: 0.4781 - val_loss: 4.8971 - val_acc: 0.3189\n","Epoch 8/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.7930 - acc: 0.4740 - val_loss: 4.7204 - val_acc: 0.3207\n","Epoch 9/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.7323 - acc: 0.4827 - val_loss: 4.6932 - val_acc: 0.3213\n","Epoch 10/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.7819 - acc: 0.4770 - val_loss: 4.4652 - val_acc: 0.3477\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 533ms/step - loss: 2.7304 - acc: 0.4782 - val_loss: 4.6445 - val_acc: 0.3260\n","Epoch 2/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.7238 - acc: 0.4848 - val_loss: 4.7222 - val_acc: 0.3281\n","Epoch 3/10\n","100/100 [==============================] - 52s 523ms/step - loss: 2.7306 - acc: 0.4783 - val_loss: 4.9218 - val_acc: 0.2997\n","Epoch 4/10\n","100/100 [==============================] - 52s 525ms/step - loss: 2.7167 - acc: 0.4842 - val_loss: 4.8282 - val_acc: 0.3128\n","Epoch 5/10\n","100/100 [==============================] - 52s 523ms/step - loss: 2.7215 - acc: 0.4843 - val_loss: 4.7308 - val_acc: 0.3214\n","Epoch 6/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.7026 - acc: 0.4865 - val_loss: 4.6983 - val_acc: 0.3293\n","Epoch 7/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.7077 - acc: 0.4852 - val_loss: 5.1486 - val_acc: 0.2793\n","Epoch 8/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.6985 - acc: 0.4868 - val_loss: 4.7832 - val_acc: 0.3190\n","Epoch 9/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.6975 - acc: 0.4870 - val_loss: 4.7198 - val_acc: 0.3301\n","Epoch 10/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.6984 - acc: 0.4890 - val_loss: 4.7737 - val_acc: 0.3325\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 526ms/step - loss: 2.6763 - acc: 0.4890 - val_loss: 4.6436 - val_acc: 0.3293\n","Epoch 2/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.6903 - acc: 0.4882 - val_loss: 4.5962 - val_acc: 0.3279\n","Epoch 3/10\n","100/100 [==============================] - 51s 513ms/step - loss: 2.6678 - acc: 0.4930 - val_loss: 4.7043 - val_acc: 0.3364\n","Epoch 4/10\n","100/100 [==============================] - 53s 531ms/step - loss: 2.6536 - acc: 0.4946 - val_loss: 4.7755 - val_acc: 0.3189\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.6506 - acc: 0.4947 - val_loss: 4.9705 - val_acc: 0.2992\n","Epoch 6/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.6403 - acc: 0.4942 - val_loss: 4.7922 - val_acc: 0.3187\n","Epoch 7/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.6437 - acc: 0.4925 - val_loss: 4.6876 - val_acc: 0.3294\n","Epoch 8/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.6536 - acc: 0.4935 - val_loss: 4.7261 - val_acc: 0.3222\n","Epoch 9/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.6236 - acc: 0.4967 - val_loss: 4.6301 - val_acc: 0.3349\n","Epoch 10/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.5976 - acc: 0.5011 - val_loss: 5.0837 - val_acc: 0.2932\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.6146 - acc: 0.4995 - val_loss: 4.7211 - val_acc: 0.3262\n","Epoch 2/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.6204 - acc: 0.4946 - val_loss: 4.6492 - val_acc: 0.3388\n","Epoch 3/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.6234 - acc: 0.4954 - val_loss: 4.8503 - val_acc: 0.3166\n","Epoch 4/10\n","100/100 [==============================] - 51s 511ms/step - loss: 2.5869 - acc: 0.5041 - val_loss: 4.9102 - val_acc: 0.3084\n","Epoch 5/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.6255 - acc: 0.4985 - val_loss: 4.7019 - val_acc: 0.3294\n","Epoch 6/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.5861 - acc: 0.5033 - val_loss: 4.6806 - val_acc: 0.3342\n","Epoch 7/10\n","100/100 [==============================] - 51s 513ms/step - loss: 2.5830 - acc: 0.5033 - val_loss: 4.7440 - val_acc: 0.3313\n","Epoch 8/10\n","100/100 [==============================] - 51s 512ms/step - loss: 2.6047 - acc: 0.4996 - val_loss: 4.7511 - val_acc: 0.3180\n","Epoch 9/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.5720 - acc: 0.5052 - val_loss: 4.7614 - val_acc: 0.3229\n","Epoch 10/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.6165 - acc: 0.4983 - val_loss: 4.7604 - val_acc: 0.3372\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 527ms/step - loss: 2.5531 - acc: 0.5074 - val_loss: 4.6507 - val_acc: 0.3395\n","Epoch 2/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.5699 - acc: 0.5063 - val_loss: 4.7360 - val_acc: 0.3241\n","Epoch 3/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.5651 - acc: 0.5034 - val_loss: 4.9596 - val_acc: 0.3092\n","Epoch 4/10\n","100/100 [==============================] - 51s 513ms/step - loss: 2.5652 - acc: 0.5056 - val_loss: 4.7132 - val_acc: 0.3295\n","Epoch 5/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.5284 - acc: 0.5104 - val_loss: 4.6641 - val_acc: 0.3344\n","Epoch 6/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.5667 - acc: 0.5073 - val_loss: 4.7405 - val_acc: 0.3348\n","Epoch 7/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.5516 - acc: 0.5085 - val_loss: 4.7402 - val_acc: 0.3291\n","Epoch 8/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.5322 - acc: 0.5114 - val_loss: 4.6930 - val_acc: 0.3353\n","Epoch 9/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.5588 - acc: 0.5065 - val_loss: 4.8404 - val_acc: 0.3186\n","Epoch 10/10\n","100/100 [==============================] - 53s 530ms/step - loss: 2.5137 - acc: 0.5125 - val_loss: 4.8867 - val_acc: 0.3135\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.5047 - acc: 0.5138 - val_loss: 4.8300 - val_acc: 0.3258\n","Epoch 2/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.5122 - acc: 0.5138 - val_loss: 4.8300 - val_acc: 0.3216\n","Epoch 3/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.5191 - acc: 0.5147 - val_loss: 4.7197 - val_acc: 0.3443\n","Epoch 4/10\n","100/100 [==============================] - 51s 512ms/step - loss: 2.5218 - acc: 0.5110 - val_loss: 4.7434 - val_acc: 0.3213\n","Epoch 5/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.4781 - acc: 0.5208 - val_loss: 4.6178 - val_acc: 0.3500\n","Epoch 6/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.4751 - acc: 0.5173 - val_loss: 4.6831 - val_acc: 0.3438\n","Epoch 7/10\n","100/100 [==============================] - 51s 511ms/step - loss: 2.4966 - acc: 0.5144 - val_loss: 4.8254 - val_acc: 0.3223\n","Epoch 8/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.4882 - acc: 0.5166 - val_loss: 4.7878 - val_acc: 0.3186\n","Epoch 9/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.4771 - acc: 0.5189 - val_loss: 4.8088 - val_acc: 0.3236\n","Epoch 10/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.4672 - acc: 0.5224 - val_loss: 4.6773 - val_acc: 0.3307\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 523ms/step - loss: 2.4686 - acc: 0.5208 - val_loss: 4.8580 - val_acc: 0.3283\n","Epoch 2/10\n","100/100 [==============================] - 51s 511ms/step - loss: 2.4664 - acc: 0.5189 - val_loss: 4.8020 - val_acc: 0.3122\n","Epoch 3/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.4858 - acc: 0.5183 - val_loss: 4.8726 - val_acc: 0.3167\n","Epoch 4/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.4327 - acc: 0.5263 - val_loss: 4.8325 - val_acc: 0.3219\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.4119 - acc: 0.5328 - val_loss: 4.8872 - val_acc: 0.3229\n","Epoch 6/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.4712 - acc: 0.5187 - val_loss: 4.8895 - val_acc: 0.3202\n","Epoch 7/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.4355 - acc: 0.5260 - val_loss: 4.9036 - val_acc: 0.3217\n","Epoch 8/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.4441 - acc: 0.5224 - val_loss: 4.8663 - val_acc: 0.3225\n","Epoch 9/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.4496 - acc: 0.5229 - val_loss: 4.7009 - val_acc: 0.3383\n","Epoch 10/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.4224 - acc: 0.5288 - val_loss: 4.8291 - val_acc: 0.3303\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 531ms/step - loss: 2.4382 - acc: 0.5227 - val_loss: 4.8130 - val_acc: 0.3317\n","Epoch 2/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.4081 - acc: 0.5310 - val_loss: 4.8429 - val_acc: 0.3203\n","Epoch 3/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.4123 - acc: 0.5307 - val_loss: 4.9612 - val_acc: 0.3133\n","Epoch 4/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.4296 - acc: 0.5256 - val_loss: 4.9266 - val_acc: 0.3232\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.4389 - acc: 0.5234 - val_loss: 4.8096 - val_acc: 0.3317\n","Epoch 6/10\n","100/100 [==============================] - 51s 513ms/step - loss: 2.4317 - acc: 0.5268 - val_loss: 4.5978 - val_acc: 0.3433\n","Epoch 7/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.4035 - acc: 0.5308 - val_loss: 4.6837 - val_acc: 0.3397\n","Epoch 8/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.3856 - acc: 0.5330 - val_loss: 4.9813 - val_acc: 0.3110\n","Epoch 9/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.4025 - acc: 0.5275 - val_loss: 4.9806 - val_acc: 0.3123\n","Epoch 10/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.3774 - acc: 0.5332 - val_loss: 4.7081 - val_acc: 0.3416\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.3782 - acc: 0.5335 - val_loss: 4.8921 - val_acc: 0.3250\n","Epoch 2/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.4126 - acc: 0.5295 - val_loss: 4.8093 - val_acc: 0.3263\n","Epoch 3/10\n","100/100 [==============================] - 53s 526ms/step - loss: 2.3950 - acc: 0.5292 - val_loss: 4.6746 - val_acc: 0.3391\n","Epoch 4/10\n","100/100 [==============================] - 52s 524ms/step - loss: 2.4076 - acc: 0.5295 - val_loss: 4.9725 - val_acc: 0.3270\n","Epoch 5/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.3792 - acc: 0.5287 - val_loss: 4.6972 - val_acc: 0.3385\n","Epoch 6/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.3833 - acc: 0.5320 - val_loss: 4.9224 - val_acc: 0.3138\n","Epoch 7/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.4035 - acc: 0.5280 - val_loss: 4.9443 - val_acc: 0.3163\n","Epoch 8/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.3496 - acc: 0.5387 - val_loss: 5.0895 - val_acc: 0.3090\n","Epoch 9/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.3755 - acc: 0.5352 - val_loss: 5.0590 - val_acc: 0.3126\n","Epoch 10/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.3515 - acc: 0.5401 - val_loss: 4.8275 - val_acc: 0.3338\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 532ms/step - loss: 2.3680 - acc: 0.5341 - val_loss: 4.7596 - val_acc: 0.3439\n","Epoch 2/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.3316 - acc: 0.5409 - val_loss: 4.7922 - val_acc: 0.3254\n","Epoch 3/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.3393 - acc: 0.5378 - val_loss: 4.7803 - val_acc: 0.3374\n","Epoch 4/10\n","100/100 [==============================] - 53s 526ms/step - loss: 2.3471 - acc: 0.5389 - val_loss: 4.9109 - val_acc: 0.3202\n","Epoch 5/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.3272 - acc: 0.5418 - val_loss: 4.9000 - val_acc: 0.3403\n","Epoch 6/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.3426 - acc: 0.5393 - val_loss: 4.8527 - val_acc: 0.3377\n","Epoch 7/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.3253 - acc: 0.5406 - val_loss: 5.0182 - val_acc: 0.3193\n","Epoch 8/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.3182 - acc: 0.5411 - val_loss: 4.8396 - val_acc: 0.3304\n","Epoch 9/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.3369 - acc: 0.5383 - val_loss: 4.8036 - val_acc: 0.3396\n","Epoch 10/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.3153 - acc: 0.5410 - val_loss: 5.0056 - val_acc: 0.3133\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 536ms/step - loss: 2.3267 - acc: 0.5393 - val_loss: 4.8731 - val_acc: 0.3215\n","Epoch 2/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.3071 - acc: 0.5428 - val_loss: 4.9267 - val_acc: 0.3314\n","Epoch 3/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.3317 - acc: 0.5394 - val_loss: 4.8569 - val_acc: 0.3237\n","Epoch 4/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.3016 - acc: 0.5456 - val_loss: 4.8793 - val_acc: 0.3272\n","Epoch 5/10\n","100/100 [==============================] - 52s 525ms/step - loss: 2.3150 - acc: 0.5430 - val_loss: 4.9732 - val_acc: 0.3220\n","Epoch 6/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.3184 - acc: 0.5427 - val_loss: 5.0322 - val_acc: 0.3174\n","Epoch 7/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.3084 - acc: 0.5409 - val_loss: 5.0523 - val_acc: 0.3057\n","Epoch 8/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2697 - acc: 0.5488 - val_loss: 4.8846 - val_acc: 0.3324\n","Epoch 9/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.2791 - acc: 0.5481 - val_loss: 4.9884 - val_acc: 0.3210\n","Epoch 10/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.2821 - acc: 0.5503 - val_loss: 5.0654 - val_acc: 0.3112\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 530ms/step - loss: 2.2924 - acc: 0.5469 - val_loss: 4.9341 - val_acc: 0.3147\n","Epoch 2/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.2638 - acc: 0.5533 - val_loss: 4.9133 - val_acc: 0.3390\n","Epoch 3/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.2653 - acc: 0.5492 - val_loss: 4.9285 - val_acc: 0.3295\n","Epoch 4/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2867 - acc: 0.5486 - val_loss: 4.9327 - val_acc: 0.3350\n","Epoch 5/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2796 - acc: 0.5477 - val_loss: 4.9552 - val_acc: 0.3220\n","Epoch 6/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.2467 - acc: 0.5535 - val_loss: 4.7017 - val_acc: 0.3466\n","Epoch 7/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.2702 - acc: 0.5509 - val_loss: 4.9414 - val_acc: 0.3107\n","Epoch 8/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.2413 - acc: 0.5555 - val_loss: 4.7976 - val_acc: 0.3334\n","Epoch 9/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2585 - acc: 0.5540 - val_loss: 4.9954 - val_acc: 0.3093\n","Epoch 10/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.2187 - acc: 0.5581 - val_loss: 4.9261 - val_acc: 0.3338\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 530ms/step - loss: 2.2455 - acc: 0.5543 - val_loss: 4.8943 - val_acc: 0.3293\n","Epoch 2/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2413 - acc: 0.5552 - val_loss: 4.8506 - val_acc: 0.3497\n","Epoch 3/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.2330 - acc: 0.5568 - val_loss: 4.8337 - val_acc: 0.3277\n","Epoch 4/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2042 - acc: 0.5615 - val_loss: 4.9229 - val_acc: 0.3283\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.2434 - acc: 0.5556 - val_loss: 4.8964 - val_acc: 0.3371\n","Epoch 6/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.2128 - acc: 0.5562 - val_loss: 4.8531 - val_acc: 0.3319\n","Epoch 7/10\n","100/100 [==============================] - 52s 517ms/step - loss: 2.2457 - acc: 0.5529 - val_loss: 4.7336 - val_acc: 0.3444\n","Epoch 8/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.2261 - acc: 0.5578 - val_loss: 4.9499 - val_acc: 0.3254\n","Epoch 9/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.2350 - acc: 0.5533 - val_loss: 5.1936 - val_acc: 0.2982\n","Epoch 10/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.2141 - acc: 0.5618 - val_loss: 5.0482 - val_acc: 0.3173\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.2285 - acc: 0.5578 - val_loss: 5.0122 - val_acc: 0.3232\n","Epoch 2/10\n","100/100 [==============================] - 51s 512ms/step - loss: 2.1991 - acc: 0.5598 - val_loss: 4.9368 - val_acc: 0.3261\n","Epoch 3/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.2093 - acc: 0.5574 - val_loss: 5.0112 - val_acc: 0.3191\n","Epoch 4/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.2017 - acc: 0.5584 - val_loss: 4.8743 - val_acc: 0.3339\n","Epoch 5/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.2059 - acc: 0.5583 - val_loss: 5.0152 - val_acc: 0.3153\n","Epoch 6/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1895 - acc: 0.5618 - val_loss: 5.0188 - val_acc: 0.3187\n","Epoch 7/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.2182 - acc: 0.5573 - val_loss: 5.0496 - val_acc: 0.3243\n","Epoch 8/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.1811 - acc: 0.5638 - val_loss: 4.6569 - val_acc: 0.3677\n","Epoch 9/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.2027 - acc: 0.5597 - val_loss: 4.8666 - val_acc: 0.3314\n","Epoch 10/10\n","100/100 [==============================] - 51s 511ms/step - loss: 2.1673 - acc: 0.5661 - val_loss: 4.8950 - val_acc: 0.3374\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.2072 - acc: 0.5569 - val_loss: 4.8212 - val_acc: 0.3398\n","Epoch 2/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1589 - acc: 0.5638 - val_loss: 4.9737 - val_acc: 0.3171\n","Epoch 3/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.1937 - acc: 0.5641 - val_loss: 4.8093 - val_acc: 0.3422\n","Epoch 4/10\n","100/100 [==============================] - 51s 512ms/step - loss: 2.1738 - acc: 0.5634 - val_loss: 5.0780 - val_acc: 0.3228\n","Epoch 5/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.1992 - acc: 0.5567 - val_loss: 5.0456 - val_acc: 0.3244\n","Epoch 6/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.1673 - acc: 0.5648 - val_loss: 4.9308 - val_acc: 0.3371\n","Epoch 7/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.1720 - acc: 0.5650 - val_loss: 4.9620 - val_acc: 0.3223\n","Epoch 8/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1927 - acc: 0.5638 - val_loss: 4.9481 - val_acc: 0.3213\n","Epoch 9/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.1621 - acc: 0.5674 - val_loss: 4.8651 - val_acc: 0.3480\n","Epoch 10/10\n","100/100 [==============================] - 51s 511ms/step - loss: 2.1646 - acc: 0.5672 - val_loss: 4.9261 - val_acc: 0.3237\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.1315 - acc: 0.5713 - val_loss: 4.9345 - val_acc: 0.3258\n","Epoch 2/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1503 - acc: 0.5688 - val_loss: 4.7837 - val_acc: 0.3550\n","Epoch 3/10\n","100/100 [==============================] - 50s 505ms/step - loss: 2.1467 - acc: 0.5717 - val_loss: 5.0057 - val_acc: 0.3200\n","Epoch 4/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.1324 - acc: 0.5673 - val_loss: 5.1728 - val_acc: 0.3095\n","Epoch 5/10\n","100/100 [==============================] - 50s 504ms/step - loss: 2.1639 - acc: 0.5660 - val_loss: 4.9672 - val_acc: 0.3250\n","Epoch 6/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1363 - acc: 0.5726 - val_loss: 4.8525 - val_acc: 0.3245\n","Epoch 7/10\n","100/100 [==============================] - 50s 504ms/step - loss: 2.1522 - acc: 0.5688 - val_loss: 4.9179 - val_acc: 0.3308\n","Epoch 8/10\n","100/100 [==============================] - 50s 505ms/step - loss: 2.1410 - acc: 0.5729 - val_loss: 4.9928 - val_acc: 0.3302\n","Epoch 9/10\n","100/100 [==============================] - 51s 505ms/step - loss: 2.1449 - acc: 0.5683 - val_loss: 4.8974 - val_acc: 0.3263\n","Epoch 10/10\n","100/100 [==============================] - 50s 504ms/step - loss: 2.1116 - acc: 0.5740 - val_loss: 4.9003 - val_acc: 0.3345\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.1403 - acc: 0.5686 - val_loss: 5.1890 - val_acc: 0.3133\n","Epoch 2/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1105 - acc: 0.5720 - val_loss: 4.9816 - val_acc: 0.3283\n","Epoch 3/10\n","100/100 [==============================] - 51s 505ms/step - loss: 2.1352 - acc: 0.5719 - val_loss: 5.0103 - val_acc: 0.3288\n","Epoch 4/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.1490 - acc: 0.5655 - val_loss: 4.9685 - val_acc: 0.3281\n","Epoch 5/10\n","100/100 [==============================] - 50s 502ms/step - loss: 2.1469 - acc: 0.5697 - val_loss: 5.1653 - val_acc: 0.3045\n","Epoch 6/10\n","100/100 [==============================] - 50s 503ms/step - loss: 2.1273 - acc: 0.5724 - val_loss: 5.1507 - val_acc: 0.3117\n","Epoch 7/10\n","100/100 [==============================] - 50s 503ms/step - loss: 2.0950 - acc: 0.5768 - val_loss: 4.9381 - val_acc: 0.3289\n","Epoch 8/10\n","100/100 [==============================] - 51s 508ms/step - loss: 2.1126 - acc: 0.5737 - val_loss: 4.9076 - val_acc: 0.3286\n","Epoch 9/10\n","100/100 [==============================] - 50s 503ms/step - loss: 2.1090 - acc: 0.5735 - val_loss: 4.9952 - val_acc: 0.3272\n","Epoch 10/10\n","100/100 [==============================] - 50s 505ms/step - loss: 2.0684 - acc: 0.5806 - val_loss: 5.1657 - val_acc: 0.3154\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 51s 512ms/step - loss: 2.0941 - acc: 0.5788 - val_loss: 4.9604 - val_acc: 0.3283\n","Epoch 2/10\n","100/100 [==============================] - 50s 503ms/step - loss: 2.0901 - acc: 0.5786 - val_loss: 4.7526 - val_acc: 0.3402\n","Epoch 3/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.0997 - acc: 0.5769 - val_loss: 5.0066 - val_acc: 0.3245\n","Epoch 4/10\n","100/100 [==============================] - 50s 504ms/step - loss: 2.0849 - acc: 0.5775 - val_loss: 5.0773 - val_acc: 0.3158\n","Epoch 5/10\n","100/100 [==============================] - 50s 500ms/step - loss: 2.1062 - acc: 0.5720 - val_loss: 5.0933 - val_acc: 0.3232\n","Epoch 6/10\n","100/100 [==============================] - 50s 501ms/step - loss: 2.1018 - acc: 0.5745 - val_loss: 5.2206 - val_acc: 0.3042\n","Epoch 7/10\n","100/100 [==============================] - 50s 500ms/step - loss: 2.0883 - acc: 0.5786 - val_loss: 5.1357 - val_acc: 0.3133\n","Epoch 8/10\n","100/100 [==============================] - 50s 501ms/step - loss: 2.0706 - acc: 0.5829 - val_loss: 5.0742 - val_acc: 0.3141\n","Epoch 9/10\n","100/100 [==============================] - 50s 500ms/step - loss: 2.0849 - acc: 0.5766 - val_loss: 5.2265 - val_acc: 0.3076\n","Epoch 10/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.0883 - acc: 0.5762 - val_loss: 5.0519 - val_acc: 0.3221\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.0957 - acc: 0.5763 - val_loss: 5.1699 - val_acc: 0.3140\n","Epoch 2/10\n","100/100 [==============================] - 51s 505ms/step - loss: 2.0856 - acc: 0.5785 - val_loss: 5.0392 - val_acc: 0.3220\n","Epoch 3/10\n","100/100 [==============================] - 50s 502ms/step - loss: 2.0862 - acc: 0.5762 - val_loss: 5.0555 - val_acc: 0.3167\n","Epoch 4/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.0732 - acc: 0.5779 - val_loss: 4.8869 - val_acc: 0.3424\n","Epoch 5/10\n","100/100 [==============================] - 51s 515ms/step - loss: 2.0545 - acc: 0.5836 - val_loss: 5.0937 - val_acc: 0.3108\n","Epoch 6/10\n","100/100 [==============================] - 50s 500ms/step - loss: 2.0799 - acc: 0.5794 - val_loss: 5.1267 - val_acc: 0.3281\n","Epoch 7/10\n","100/100 [==============================] - 51s 513ms/step - loss: 2.0472 - acc: 0.5830 - val_loss: 4.9841 - val_acc: 0.3333\n","Epoch 8/10\n","100/100 [==============================] - 51s 514ms/step - loss: 2.0759 - acc: 0.5802 - val_loss: 4.9964 - val_acc: 0.3285\n","Epoch 9/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.0661 - acc: 0.5805 - val_loss: 5.0912 - val_acc: 0.3269\n","Epoch 10/10\n","100/100 [==============================] - 51s 512ms/step - loss: 2.0416 - acc: 0.5822 - val_loss: 4.9090 - val_acc: 0.3363\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 52s 522ms/step - loss: 2.0514 - acc: 0.5853 - val_loss: 4.9422 - val_acc: 0.3299\n","Epoch 2/10\n","100/100 [==============================] - 51s 509ms/step - loss: 2.0624 - acc: 0.5832 - val_loss: 5.0547 - val_acc: 0.3353\n","Epoch 3/10\n","100/100 [==============================] - 51s 511ms/step - loss: 2.0937 - acc: 0.5736 - val_loss: 5.2215 - val_acc: 0.3162\n","Epoch 4/10\n","100/100 [==============================] - 51s 510ms/step - loss: 2.0483 - acc: 0.5826 - val_loss: 5.1615 - val_acc: 0.3263\n","Epoch 5/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.0415 - acc: 0.5870 - val_loss: 5.0176 - val_acc: 0.3343\n","Epoch 6/10\n","100/100 [==============================] - 51s 506ms/step - loss: 2.0726 - acc: 0.5803 - val_loss: 5.0790 - val_acc: 0.3198\n","Epoch 7/10\n","100/100 [==============================] - 51s 507ms/step - loss: 2.0462 - acc: 0.5841 - val_loss: 4.9674 - val_acc: 0.3261\n","Epoch 8/10\n","100/100 [==============================] - 52s 516ms/step - loss: 1.9970 - acc: 0.5944 - val_loss: 5.1217 - val_acc: 0.3165\n","Epoch 9/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.0273 - acc: 0.5853 - val_loss: 4.9855 - val_acc: 0.3323\n","Epoch 10/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.0101 - acc: 0.5887 - val_loss: 5.1404 - val_acc: 0.3158\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 528ms/step - loss: 2.0048 - acc: 0.5902 - val_loss: 4.9326 - val_acc: 0.3433\n","Epoch 2/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.0177 - acc: 0.5867 - val_loss: 4.9261 - val_acc: 0.3321\n","Epoch 3/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.0773 - acc: 0.5774 - val_loss: 4.9842 - val_acc: 0.3442\n","Epoch 4/10\n","100/100 [==============================] - 52s 515ms/step - loss: 2.0361 - acc: 0.5860 - val_loss: 4.8964 - val_acc: 0.3384\n","Epoch 5/10\n","100/100 [==============================] - 52s 519ms/step - loss: 2.0501 - acc: 0.5823 - val_loss: 5.0481 - val_acc: 0.3233\n","Epoch 6/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.0451 - acc: 0.5861 - val_loss: 5.0910 - val_acc: 0.3320\n","Epoch 7/10\n","100/100 [==============================] - 52s 516ms/step - loss: 2.0354 - acc: 0.5873 - val_loss: 5.2624 - val_acc: 0.3089\n","Epoch 8/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.0476 - acc: 0.5849 - val_loss: 5.1298 - val_acc: 0.3107\n","Epoch 9/10\n","100/100 [==============================] - 52s 518ms/step - loss: 2.0387 - acc: 0.5854 - val_loss: 5.0693 - val_acc: 0.3214\n","Epoch 10/10\n","100/100 [==============================] - 54s 536ms/step - loss: 2.0222 - acc: 0.5911 - val_loss: 5.0509 - val_acc: 0.3261\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 56s 556ms/step - loss: 2.0448 - acc: 0.5812 - val_loss: 5.0834 - val_acc: 0.3315\n","Epoch 2/10\n","100/100 [==============================] - 54s 538ms/step - loss: 2.0290 - acc: 0.5837 - val_loss: 4.9792 - val_acc: 0.3319\n","Epoch 3/10\n","100/100 [==============================] - 54s 537ms/step - loss: 1.9925 - acc: 0.5902 - val_loss: 5.1674 - val_acc: 0.3270\n","Epoch 4/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.9877 - acc: 0.5941 - val_loss: 4.8880 - val_acc: 0.3540\n","Epoch 5/10\n","100/100 [==============================] - 54s 539ms/step - loss: 1.9932 - acc: 0.5935 - val_loss: 4.8031 - val_acc: 0.3523\n","Epoch 6/10\n","100/100 [==============================] - 54s 539ms/step - loss: 1.9827 - acc: 0.5924 - val_loss: 4.8520 - val_acc: 0.3444\n","Epoch 7/10\n","100/100 [==============================] - 53s 531ms/step - loss: 1.9818 - acc: 0.5979 - val_loss: 5.0667 - val_acc: 0.3267\n","Epoch 8/10\n","100/100 [==============================] - 52s 525ms/step - loss: 1.9615 - acc: 0.5959 - val_loss: 5.0794 - val_acc: 0.3305\n","Epoch 9/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.9871 - acc: 0.5932 - val_loss: 5.0301 - val_acc: 0.3347\n","Epoch 10/10\n","100/100 [==============================] - 53s 528ms/step - loss: 1.9694 - acc: 0.5931 - val_loss: 5.1169 - val_acc: 0.3238\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 531ms/step - loss: 2.0050 - acc: 0.5894 - val_loss: 5.0895 - val_acc: 0.3318\n","Epoch 2/10\n","100/100 [==============================] - 52s 521ms/step - loss: 2.0067 - acc: 0.5901 - val_loss: 5.0868 - val_acc: 0.3223\n","Epoch 3/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.9614 - acc: 0.5972 - val_loss: 5.1007 - val_acc: 0.3241\n","Epoch 4/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.9893 - acc: 0.5898 - val_loss: 5.1753 - val_acc: 0.3262\n","Epoch 5/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.9725 - acc: 0.5922 - val_loss: 5.0947 - val_acc: 0.3362\n","Epoch 6/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.9678 - acc: 0.5955 - val_loss: 5.1234 - val_acc: 0.3378\n","Epoch 7/10\n","100/100 [==============================] - 52s 520ms/step - loss: 2.0252 - acc: 0.5879 - val_loss: 5.0412 - val_acc: 0.3286\n","Epoch 8/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.9687 - acc: 0.5943 - val_loss: 5.1965 - val_acc: 0.3152\n","Epoch 9/10\n","100/100 [==============================] - 52s 516ms/step - loss: 1.9735 - acc: 0.5962 - val_loss: 5.2900 - val_acc: 0.3136\n","Epoch 10/10\n","100/100 [==============================] - 52s 517ms/step - loss: 1.9893 - acc: 0.5905 - val_loss: 5.0808 - val_acc: 0.3105\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 56s 563ms/step - loss: 1.9441 - acc: 0.6010 - val_loss: 5.1528 - val_acc: 0.3208\n","Epoch 2/10\n","100/100 [==============================] - 53s 535ms/step - loss: 1.9956 - acc: 0.5912 - val_loss: 5.2740 - val_acc: 0.3227\n","Epoch 3/10\n","100/100 [==============================] - 54s 538ms/step - loss: 1.9707 - acc: 0.5931 - val_loss: 5.2134 - val_acc: 0.3169\n","Epoch 4/10\n","100/100 [==============================] - 53s 533ms/step - loss: 1.9458 - acc: 0.5978 - val_loss: 4.9251 - val_acc: 0.3445\n","Epoch 5/10\n","100/100 [==============================] - 53s 532ms/step - loss: 1.9651 - acc: 0.5989 - val_loss: 5.1849 - val_acc: 0.3200\n","Epoch 6/10\n","100/100 [==============================] - 55s 549ms/step - loss: 1.9671 - acc: 0.5935 - val_loss: 5.2335 - val_acc: 0.3068\n","Epoch 7/10\n","100/100 [==============================] - 53s 530ms/step - loss: 1.9506 - acc: 0.5945 - val_loss: 4.9285 - val_acc: 0.3410\n","Epoch 8/10\n","100/100 [==============================] - 52s 525ms/step - loss: 1.9607 - acc: 0.5953 - val_loss: 5.0766 - val_acc: 0.3270\n","Epoch 9/10\n","100/100 [==============================] - 53s 527ms/step - loss: 1.9543 - acc: 0.5979 - val_loss: 5.0959 - val_acc: 0.3244\n","Epoch 10/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.9520 - acc: 0.5993 - val_loss: 5.4040 - val_acc: 0.3133\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 55s 547ms/step - loss: 1.9642 - acc: 0.5940 - val_loss: 5.1283 - val_acc: 0.3321\n","Epoch 2/10\n","100/100 [==============================] - 53s 533ms/step - loss: 1.9354 - acc: 0.5983 - val_loss: 5.1981 - val_acc: 0.3189\n","Epoch 3/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.9235 - acc: 0.6021 - val_loss: 4.9941 - val_acc: 0.3231\n","Epoch 4/10\n","100/100 [==============================] - 53s 525ms/step - loss: 1.9204 - acc: 0.6032 - val_loss: 5.2232 - val_acc: 0.3209\n","Epoch 5/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.9510 - acc: 0.5973 - val_loss: 5.2415 - val_acc: 0.3294\n","Epoch 6/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.9480 - acc: 0.5981 - val_loss: 5.1340 - val_acc: 0.3248\n","Epoch 7/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.9549 - acc: 0.5946 - val_loss: 5.0563 - val_acc: 0.3435\n","Epoch 8/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.9427 - acc: 0.5998 - val_loss: 5.1959 - val_acc: 0.3210\n","Epoch 9/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.9313 - acc: 0.6032 - val_loss: 5.2360 - val_acc: 0.3145\n","Epoch 10/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.9407 - acc: 0.5984 - val_loss: 5.3224 - val_acc: 0.3015\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 55s 550ms/step - loss: 1.9366 - acc: 0.5987 - val_loss: 5.1356 - val_acc: 0.3292\n","Epoch 2/10\n","100/100 [==============================] - 55s 545ms/step - loss: 1.9077 - acc: 0.6038 - val_loss: 5.2068 - val_acc: 0.3210\n","Epoch 3/10\n","100/100 [==============================] - 54s 541ms/step - loss: 1.9228 - acc: 0.6021 - val_loss: 5.1828 - val_acc: 0.3276\n","Epoch 4/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.9239 - acc: 0.6009 - val_loss: 5.3324 - val_acc: 0.3096\n","Epoch 5/10\n","100/100 [==============================] - 54s 544ms/step - loss: 1.8995 - acc: 0.6067 - val_loss: 5.2599 - val_acc: 0.3207\n","Epoch 6/10\n","100/100 [==============================] - 54s 538ms/step - loss: 1.9457 - acc: 0.5980 - val_loss: 5.0787 - val_acc: 0.3295\n","Epoch 7/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.9355 - acc: 0.5981 - val_loss: 5.2146 - val_acc: 0.3189\n","Epoch 8/10\n","100/100 [==============================] - 53s 528ms/step - loss: 1.9155 - acc: 0.6048 - val_loss: 5.3864 - val_acc: 0.3190\n","Epoch 9/10\n","100/100 [==============================] - 53s 527ms/step - loss: 1.9087 - acc: 0.6069 - val_loss: 5.2852 - val_acc: 0.3180\n","Epoch 10/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.8926 - acc: 0.6052 - val_loss: 5.1817 - val_acc: 0.3284\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 540ms/step - loss: 1.8846 - acc: 0.6072 - val_loss: 5.1724 - val_acc: 0.3328\n","Epoch 2/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.8858 - acc: 0.6078 - val_loss: 5.1424 - val_acc: 0.3297\n","Epoch 3/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.9116 - acc: 0.6078 - val_loss: 5.1182 - val_acc: 0.3196\n","Epoch 4/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.9128 - acc: 0.6028 - val_loss: 5.3507 - val_acc: 0.3061\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 1.8820 - acc: 0.6090 - val_loss: 5.0418 - val_acc: 0.3424\n","Epoch 6/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.8918 - acc: 0.6061 - val_loss: 5.1050 - val_acc: 0.3383\n","Epoch 7/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8855 - acc: 0.6061 - val_loss: 5.1569 - val_acc: 0.3205\n","Epoch 8/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.8821 - acc: 0.6110 - val_loss: 5.0615 - val_acc: 0.3308\n","Epoch 9/10\n","100/100 [==============================] - 52s 525ms/step - loss: 1.9297 - acc: 0.6015 - val_loss: 5.2825 - val_acc: 0.3250\n","Epoch 10/10\n","100/100 [==============================] - 52s 524ms/step - loss: 1.8764 - acc: 0.6116 - val_loss: 5.2063 - val_acc: 0.3340\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 534ms/step - loss: 1.8833 - acc: 0.6101 - val_loss: 5.3313 - val_acc: 0.3198\n","Epoch 2/10\n","100/100 [==============================] - 53s 531ms/step - loss: 1.9100 - acc: 0.6029 - val_loss: 5.1141 - val_acc: 0.3332\n","Epoch 3/10\n","100/100 [==============================] - 55s 553ms/step - loss: 1.8901 - acc: 0.6082 - val_loss: 5.2498 - val_acc: 0.3212\n","Epoch 4/10\n","100/100 [==============================] - 54s 542ms/step - loss: 1.8873 - acc: 0.6057 - val_loss: 5.1385 - val_acc: 0.3304\n","Epoch 5/10\n","100/100 [==============================] - 54s 539ms/step - loss: 1.8599 - acc: 0.6111 - val_loss: 5.1370 - val_acc: 0.3240\n","Epoch 6/10\n","100/100 [==============================] - 54s 537ms/step - loss: 1.9059 - acc: 0.6059 - val_loss: 5.2921 - val_acc: 0.3239\n","Epoch 7/10\n","100/100 [==============================] - 54s 540ms/step - loss: 1.8564 - acc: 0.6128 - val_loss: 5.2401 - val_acc: 0.3187\n","Epoch 8/10\n","100/100 [==============================] - 54s 540ms/step - loss: 1.8919 - acc: 0.6096 - val_loss: 5.2753 - val_acc: 0.3305\n","Epoch 9/10\n","100/100 [==============================] - 53s 535ms/step - loss: 1.8712 - acc: 0.6072 - val_loss: 5.1846 - val_acc: 0.3252\n","Epoch 10/10\n","100/100 [==============================] - 53s 533ms/step - loss: 1.8833 - acc: 0.6117 - val_loss: 5.2912 - val_acc: 0.3180\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.8413 - acc: 0.6166 - val_loss: 5.2017 - val_acc: 0.3097\n","Epoch 2/10\n","100/100 [==============================] - 53s 529ms/step - loss: 1.8721 - acc: 0.6110 - val_loss: 5.1633 - val_acc: 0.3298\n","Epoch 3/10\n","100/100 [==============================] - 53s 525ms/step - loss: 1.8548 - acc: 0.6141 - val_loss: 5.2883 - val_acc: 0.3161\n","Epoch 4/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8243 - acc: 0.6198 - val_loss: 5.3332 - val_acc: 0.3260\n","Epoch 5/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.8610 - acc: 0.6113 - val_loss: 5.3554 - val_acc: 0.3130\n","Epoch 6/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.8436 - acc: 0.6127 - val_loss: 5.0672 - val_acc: 0.3425\n","Epoch 7/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8586 - acc: 0.6121 - val_loss: 5.4176 - val_acc: 0.3121\n","Epoch 8/10\n","100/100 [==============================] - 53s 527ms/step - loss: 1.8583 - acc: 0.6125 - val_loss: 5.2039 - val_acc: 0.3323\n","Epoch 9/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.9027 - acc: 0.6050 - val_loss: 5.4528 - val_acc: 0.3034\n","Epoch 10/10\n","100/100 [==============================] - 52s 516ms/step - loss: 1.8323 - acc: 0.6173 - val_loss: 5.3347 - val_acc: 0.3165\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 544ms/step - loss: 1.8585 - acc: 0.6146 - val_loss: 5.0169 - val_acc: 0.3367\n","Epoch 2/10\n","100/100 [==============================] - 53s 534ms/step - loss: 1.8523 - acc: 0.6122 - val_loss: 5.2918 - val_acc: 0.3236\n","Epoch 3/10\n","100/100 [==============================] - 52s 517ms/step - loss: 1.8622 - acc: 0.6098 - val_loss: 5.1261 - val_acc: 0.3331\n","Epoch 4/10\n","100/100 [==============================] - 55s 548ms/step - loss: 1.8501 - acc: 0.6159 - val_loss: 5.0419 - val_acc: 0.3284\n","Epoch 5/10\n","100/100 [==============================] - 53s 533ms/step - loss: 1.8651 - acc: 0.6117 - val_loss: 5.2417 - val_acc: 0.3248\n","Epoch 6/10\n","100/100 [==============================] - 54s 538ms/step - loss: 1.8696 - acc: 0.6128 - val_loss: 5.3080 - val_acc: 0.3262\n","Epoch 7/10\n","100/100 [==============================] - 54s 545ms/step - loss: 1.8448 - acc: 0.6163 - val_loss: 5.1360 - val_acc: 0.3349\n","Epoch 8/10\n","100/100 [==============================] - 55s 545ms/step - loss: 1.8220 - acc: 0.6212 - val_loss: 5.2487 - val_acc: 0.3192\n","Epoch 9/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.8440 - acc: 0.6141 - val_loss: 5.4084 - val_acc: 0.3129\n","Epoch 10/10\n","100/100 [==============================] - 53s 535ms/step - loss: 1.8232 - acc: 0.6175 - val_loss: 5.1112 - val_acc: 0.3366\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 544ms/step - loss: 1.8718 - acc: 0.6108 - val_loss: 5.0488 - val_acc: 0.3420\n","Epoch 2/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.8136 - acc: 0.6213 - val_loss: 5.1878 - val_acc: 0.3188\n","Epoch 3/10\n","100/100 [==============================] - 53s 531ms/step - loss: 1.8221 - acc: 0.6173 - val_loss: 5.1764 - val_acc: 0.3367\n","Epoch 4/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8666 - acc: 0.6102 - val_loss: 5.2248 - val_acc: 0.3282\n","Epoch 5/10\n","100/100 [==============================] - 52s 524ms/step - loss: 1.8450 - acc: 0.6112 - val_loss: 5.2952 - val_acc: 0.3199\n","Epoch 6/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.8342 - acc: 0.6172 - val_loss: 5.1655 - val_acc: 0.3272\n","Epoch 7/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.8440 - acc: 0.6145 - val_loss: 5.3989 - val_acc: 0.3080\n","Epoch 8/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.8421 - acc: 0.6133 - val_loss: 5.3216 - val_acc: 0.3197\n","Epoch 9/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8058 - acc: 0.6192 - val_loss: 5.2545 - val_acc: 0.3349\n","Epoch 10/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.8469 - acc: 0.6168 - val_loss: 5.2537 - val_acc: 0.3188\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 532ms/step - loss: 1.8450 - acc: 0.6160 - val_loss: 5.1218 - val_acc: 0.3302\n","Epoch 2/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.8380 - acc: 0.6152 - val_loss: 5.2279 - val_acc: 0.3252\n","Epoch 3/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.8106 - acc: 0.6206 - val_loss: 5.3438 - val_acc: 0.3186\n","Epoch 4/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8227 - acc: 0.6192 - val_loss: 5.3367 - val_acc: 0.3120\n","Epoch 5/10\n","100/100 [==============================] - 55s 551ms/step - loss: 1.8069 - acc: 0.6204 - val_loss: 5.2674 - val_acc: 0.3231\n","Epoch 6/10\n","100/100 [==============================] - 54s 542ms/step - loss: 1.7977 - acc: 0.6212 - val_loss: 5.2035 - val_acc: 0.3212\n","Epoch 7/10\n","100/100 [==============================] - 54s 539ms/step - loss: 1.8374 - acc: 0.6170 - val_loss: 5.3123 - val_acc: 0.3246\n","Epoch 8/10\n","100/100 [==============================] - 54s 539ms/step - loss: 1.7945 - acc: 0.6236 - val_loss: 5.3298 - val_acc: 0.3194\n","Epoch 9/10\n","100/100 [==============================] - 54s 538ms/step - loss: 1.8003 - acc: 0.6243 - val_loss: 5.1952 - val_acc: 0.3298\n","Epoch 10/10\n","100/100 [==============================] - 54s 538ms/step - loss: 1.8079 - acc: 0.6199 - val_loss: 5.2237 - val_acc: 0.3220\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 55s 551ms/step - loss: 1.8061 - acc: 0.6186 - val_loss: 5.1572 - val_acc: 0.3339\n","Epoch 2/10\n","100/100 [==============================] - 53s 529ms/step - loss: 1.7965 - acc: 0.6226 - val_loss: 5.3824 - val_acc: 0.3254\n","Epoch 3/10\n","100/100 [==============================] - 52s 524ms/step - loss: 1.8205 - acc: 0.6164 - val_loss: 5.2352 - val_acc: 0.3438\n","Epoch 4/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.8056 - acc: 0.6177 - val_loss: 5.1355 - val_acc: 0.3342\n","Epoch 5/10\n","100/100 [==============================] - 53s 528ms/step - loss: 1.7982 - acc: 0.6228 - val_loss: 5.2143 - val_acc: 0.3377\n","Epoch 6/10\n","100/100 [==============================] - 53s 531ms/step - loss: 1.7735 - acc: 0.6260 - val_loss: 5.3266 - val_acc: 0.3186\n","Epoch 7/10\n","100/100 [==============================] - 52s 525ms/step - loss: 1.7874 - acc: 0.6210 - val_loss: 5.4435 - val_acc: 0.3009\n","Epoch 8/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.8078 - acc: 0.6218 - val_loss: 5.3547 - val_acc: 0.3158\n","Epoch 9/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.8088 - acc: 0.6208 - val_loss: 5.0923 - val_acc: 0.3438\n","Epoch 10/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.7856 - acc: 0.6231 - val_loss: 5.1975 - val_acc: 0.3327\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 535ms/step - loss: 1.7915 - acc: 0.6234 - val_loss: 5.1809 - val_acc: 0.3399\n","Epoch 2/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.8029 - acc: 0.6206 - val_loss: 5.2102 - val_acc: 0.3311\n","Epoch 3/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.7772 - acc: 0.6273 - val_loss: 5.2261 - val_acc: 0.3313\n","Epoch 4/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.7863 - acc: 0.6219 - val_loss: 5.3632 - val_acc: 0.3174\n","Epoch 5/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.7784 - acc: 0.6259 - val_loss: 5.0743 - val_acc: 0.3455\n","Epoch 6/10\n","100/100 [==============================] - 54s 540ms/step - loss: 1.7713 - acc: 0.6255 - val_loss: 5.3380 - val_acc: 0.3190\n","Epoch 7/10\n","100/100 [==============================] - 55s 548ms/step - loss: 1.7724 - acc: 0.6277 - val_loss: 5.1647 - val_acc: 0.3379\n","Epoch 8/10\n","100/100 [==============================] - 54s 543ms/step - loss: 1.7771 - acc: 0.6262 - val_loss: 5.1689 - val_acc: 0.3276\n","Epoch 9/10\n","100/100 [==============================] - 54s 538ms/step - loss: 1.7644 - acc: 0.6293 - val_loss: 5.2380 - val_acc: 0.3275\n","Epoch 10/10\n","100/100 [==============================] - 54s 540ms/step - loss: 1.7937 - acc: 0.6218 - val_loss: 5.2011 - val_acc: 0.3263\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 55s 551ms/step - loss: 1.8042 - acc: 0.6193 - val_loss: 5.4811 - val_acc: 0.3115\n","Epoch 2/10\n","100/100 [==============================] - 54s 539ms/step - loss: 1.8048 - acc: 0.6188 - val_loss: 5.1195 - val_acc: 0.3430\n","Epoch 3/10\n","100/100 [==============================] - 54s 536ms/step - loss: 1.7820 - acc: 0.6222 - val_loss: 5.3169 - val_acc: 0.3228\n","Epoch 4/10\n","100/100 [==============================] - 53s 530ms/step - loss: 1.7624 - acc: 0.6305 - val_loss: 5.3380 - val_acc: 0.3262\n","Epoch 5/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.7633 - acc: 0.6270 - val_loss: 5.2316 - val_acc: 0.3427\n","Epoch 6/10\n","100/100 [==============================] - 53s 526ms/step - loss: 1.7911 - acc: 0.6235 - val_loss: 5.3814 - val_acc: 0.3117\n","Epoch 7/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7890 - acc: 0.6219 - val_loss: 5.1851 - val_acc: 0.3299\n","Epoch 8/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7658 - acc: 0.6286 - val_loss: 5.2148 - val_acc: 0.3322\n","Epoch 9/10\n","100/100 [==============================] - 53s 530ms/step - loss: 1.7722 - acc: 0.6248 - val_loss: 5.3647 - val_acc: 0.3179\n","Epoch 10/10\n","100/100 [==============================] - 53s 527ms/step - loss: 1.7709 - acc: 0.6282 - val_loss: 5.2158 - val_acc: 0.3337\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 532ms/step - loss: 1.7602 - acc: 0.6297 - val_loss: 5.3675 - val_acc: 0.3317\n","Epoch 2/10\n","100/100 [==============================] - 53s 525ms/step - loss: 1.7538 - acc: 0.6308 - val_loss: 5.2842 - val_acc: 0.3238\n","Epoch 3/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.7736 - acc: 0.6249 - val_loss: 5.3561 - val_acc: 0.3167\n","Epoch 4/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.7479 - acc: 0.6305 - val_loss: 5.3873 - val_acc: 0.3273\n","Epoch 5/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7436 - acc: 0.6305 - val_loss: 5.4131 - val_acc: 0.3086\n","Epoch 6/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.7599 - acc: 0.6295 - val_loss: 5.3365 - val_acc: 0.3210\n","Epoch 7/10\n","100/100 [==============================] - 52s 523ms/step - loss: 1.7733 - acc: 0.6262 - val_loss: 5.3716 - val_acc: 0.3133\n","Epoch 8/10\n","100/100 [==============================] - 52s 524ms/step - loss: 1.7655 - acc: 0.6279 - val_loss: 5.1972 - val_acc: 0.3474\n","Epoch 9/10\n","100/100 [==============================] - 53s 528ms/step - loss: 1.7367 - acc: 0.6308 - val_loss: 5.3449 - val_acc: 0.3201\n","Epoch 10/10\n","100/100 [==============================] - 53s 526ms/step - loss: 1.7209 - acc: 0.6303 - val_loss: 5.4648 - val_acc: 0.3260\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 543ms/step - loss: 1.7438 - acc: 0.6289 - val_loss: 5.1893 - val_acc: 0.3408\n","Epoch 2/10\n","100/100 [==============================] - 53s 527ms/step - loss: 1.7183 - acc: 0.6344 - val_loss: 5.3912 - val_acc: 0.3180\n","Epoch 3/10\n","100/100 [==============================] - 53s 526ms/step - loss: 1.7592 - acc: 0.6285 - val_loss: 5.2368 - val_acc: 0.3414\n","Epoch 4/10\n","100/100 [==============================] - 52s 524ms/step - loss: 1.7233 - acc: 0.6339 - val_loss: 5.2989 - val_acc: 0.3198\n","Epoch 5/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7475 - acc: 0.6311 - val_loss: 5.5036 - val_acc: 0.3129\n","Epoch 6/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7352 - acc: 0.6320 - val_loss: 5.1663 - val_acc: 0.3323\n","Epoch 7/10\n","100/100 [==============================] - 52s 525ms/step - loss: 1.7306 - acc: 0.6322 - val_loss: 5.5136 - val_acc: 0.3042\n","Epoch 8/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7457 - acc: 0.6313 - val_loss: 5.5142 - val_acc: 0.3152\n","Epoch 9/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7732 - acc: 0.6263 - val_loss: 5.0670 - val_acc: 0.3422\n","Epoch 10/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.7261 - acc: 0.6340 - val_loss: 5.6288 - val_acc: 0.2977\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 530ms/step - loss: 1.7185 - acc: 0.6336 - val_loss: 5.2166 - val_acc: 0.3277\n","Epoch 2/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.7531 - acc: 0.6286 - val_loss: 5.3552 - val_acc: 0.3162\n","Epoch 3/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.7395 - acc: 0.6311 - val_loss: 5.5742 - val_acc: 0.3082\n","Epoch 4/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7573 - acc: 0.6291 - val_loss: 5.0614 - val_acc: 0.3471\n","Epoch 5/10\n","100/100 [==============================] - 52s 517ms/step - loss: 1.7510 - acc: 0.6302 - val_loss: 5.3205 - val_acc: 0.3263\n","Epoch 6/10\n","100/100 [==============================] - 51s 515ms/step - loss: 1.7538 - acc: 0.6276 - val_loss: 5.3261 - val_acc: 0.3191\n","Epoch 7/10\n","100/100 [==============================] - 52s 517ms/step - loss: 1.7520 - acc: 0.6305 - val_loss: 5.3060 - val_acc: 0.3251\n","Epoch 8/10\n","100/100 [==============================] - 53s 526ms/step - loss: 1.7324 - acc: 0.6333 - val_loss: 5.5762 - val_acc: 0.3061\n","Epoch 9/10\n","100/100 [==============================] - 53s 528ms/step - loss: 1.7453 - acc: 0.6317 - val_loss: 5.3318 - val_acc: 0.3086\n","Epoch 10/10\n","100/100 [==============================] - 53s 530ms/step - loss: 1.7203 - acc: 0.6340 - val_loss: 5.4800 - val_acc: 0.3051\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 543ms/step - loss: 1.7172 - acc: 0.6354 - val_loss: 5.4753 - val_acc: 0.3097\n","Epoch 2/10\n","100/100 [==============================] - 53s 529ms/step - loss: 1.7015 - acc: 0.6385 - val_loss: 5.3739 - val_acc: 0.3206\n","Epoch 3/10\n","100/100 [==============================] - 53s 531ms/step - loss: 1.7112 - acc: 0.6354 - val_loss: 5.4179 - val_acc: 0.3221\n","Epoch 4/10\n","100/100 [==============================] - 53s 529ms/step - loss: 1.7343 - acc: 0.6322 - val_loss: 5.3893 - val_acc: 0.3187\n","Epoch 5/10\n","100/100 [==============================] - 52s 525ms/step - loss: 1.7302 - acc: 0.6321 - val_loss: 5.2980 - val_acc: 0.3321\n","Epoch 6/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.7117 - acc: 0.6376 - val_loss: 5.3582 - val_acc: 0.3235\n","Epoch 7/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7328 - acc: 0.6312 - val_loss: 5.3951 - val_acc: 0.3199\n","Epoch 8/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.7326 - acc: 0.6347 - val_loss: 5.4590 - val_acc: 0.3164\n","Epoch 9/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7301 - acc: 0.6330 - val_loss: 5.2347 - val_acc: 0.3281\n","Epoch 10/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7143 - acc: 0.6330 - val_loss: 5.2472 - val_acc: 0.3333\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 53s 531ms/step - loss: 1.6833 - acc: 0.6403 - val_loss: 5.3540 - val_acc: 0.3251\n","Epoch 2/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.6824 - acc: 0.6396 - val_loss: 5.2856 - val_acc: 0.3384\n","Epoch 3/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.7278 - acc: 0.6310 - val_loss: 5.3971 - val_acc: 0.3248\n","Epoch 4/10\n","100/100 [==============================] - 52s 517ms/step - loss: 1.7080 - acc: 0.6345 - val_loss: 5.3285 - val_acc: 0.3275\n","Epoch 5/10\n","100/100 [==============================] - 52s 521ms/step - loss: 1.7037 - acc: 0.6386 - val_loss: 5.2984 - val_acc: 0.3283\n","Epoch 6/10\n","100/100 [==============================] - 52s 520ms/step - loss: 1.7273 - acc: 0.6341 - val_loss: 5.5373 - val_acc: 0.3165\n","Epoch 7/10\n","100/100 [==============================] - 52s 522ms/step - loss: 1.6899 - acc: 0.6370 - val_loss: 5.2922 - val_acc: 0.3374\n","Epoch 8/10\n","100/100 [==============================] - 52s 518ms/step - loss: 1.7099 - acc: 0.6359 - val_loss: 5.4357 - val_acc: 0.3150\n","Epoch 9/10\n","100/100 [==============================] - 52s 519ms/step - loss: 1.7111 - acc: 0.6356 - val_loss: 5.5567 - val_acc: 0.3129\n","Epoch 10/10\n","100/100 [==============================] - 53s 532ms/step - loss: 1.6970 - acc: 0.6384 - val_loss: 5.2122 - val_acc: 0.3424\n","saving model weights ....\n","saving model weights completed....\n","saving plot info ....\n","saving plot info completed ....\n","Epoch 1/10\n","100/100 [==============================] - 54s 541ms/step - loss: 1.7386 - acc: 0.6302 - val_loss: 5.4411 - val_acc: 0.3206\n","Epoch 2/10\n","100/100 [==============================] - 53s 529ms/step - loss: 1.7245 - acc: 0.6322 - val_loss: 5.5553 - val_acc: 0.3165\n","Epoch 3/10\n"," 18/100 [====>.........................] - ETA: 41s - loss: 1.6604 - acc: 0.6455Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"metadata":{"id":"pFaVD44msXSD","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_loss_acc(hist):\n","    f, ax = plt.subplots()\n","    ax.plot([None] + hist.history['acc'], 'o-')\n","    ax.plot([None] + hist.history['val_acc'], 'x-')\n","    # Plot legend and use the best location automatically: loc = 0.\n","    ax.legend(['Train acc', 'Validation acc'], loc = 0)\n","    ax.set_title('Training/Validation acc per Epoch')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Acc') \n","    plt.plot()\n","    \n","    f, ax = plt.subplots()\n","    ax.plot([None] + hist.history['loss'], 'o-',c='r')\n","    ax.plot([None] + hist.history['val_loss'], 'x-',c='g')\n","    # Plot legend and use the best location automatically: loc = 0.\n","    ax.legend(['Train loss', 'Validation loss'], loc = 0)\n","    ax.set_title('Training/Validation loss per Epoch')\n","    ax.set_xlabel('Epoch')\n","    ax.set_ylabel('Acc') \n","    plt.plot()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q8hLOiles1IH","colab_type":"code","outputId":"e0f9839f-110e-4326-e66e-85734132118f","executionInfo":{"status":"ok","timestamp":1555709060569,"user_tz":420,"elapsed":1732,"user":{"displayName":"SHUN LIN","photoUrl":"https://lh4.googleusercontent.com/-pkp40ccE7So/AAAAAAAAAAI/AAAAAAAAAU4/Upp1QcV6fHs/s64/photo.jpg","userId":"16137932526864003348"}},"colab":{"base_uri":"https://localhost:8080/","height":590}},"cell_type":"code","source":["history = pd.read_csv(plot_info_path)\n","history = history.groupby(np.arange(len(history))//20).mean()\n","f, ax = plt.subplots()\n","ax.plot(history['training_acc'], 'o-')\n","ax.plot(history['validation_acc'], 'o-')\n","# Plot legend and use the best location automatically: loc = 0.\n","ax.legend(['Train acc', 'Validation acc'], loc = 0)\n","ax.set_title('Training/Validation acc per Epoch')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Acc') \n","plt.plot()\n","\n","f, ax = plt.subplots()\n","ax.plot(history['training_err'], 'o-',c='r')\n","ax.plot(history['validation_err'], 'o-',c='g')\n","# Plot legend and use the best location automatically: loc = 0.\n","ax.legend(['Train loss', 'Validation loss'], loc = 0)\n","ax.set_title('Training/Validation loss per Epoch')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Acc') \n","plt.plot()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":30},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm/IxAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"HLeYPtaqRKbp","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"4pqaiphXRHYK","colab_type":"code","outputId":"4bd7183a-9c42-4b48-f301-30201248d928","executionInfo":{"status":"ok","timestamp":1555709067131,"user_tz":420,"elapsed":5486,"user":{"displayName":"SHUN LIN","photoUrl":"https://lh4.googleusercontent.com/-pkp40ccE7So/AAAAAAAAAAI/AAAAAAAAAU4/Upp1QcV6fHs/s64/photo.jpg","userId":"16137932526864003348"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["model.save(root_folder + 'models/keras_model.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_4:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"}]},{"metadata":{"id":"W9PToaG7s4Ce","colab_type":"code","outputId":"596bfe06-b46a-4054-e33f-60825c3aa992","executionInfo":{"status":"error","timestamp":1555709067494,"user_tz":420,"elapsed":5121,"user":{"displayName":"SHUN LIN","photoUrl":"https://lh4.googleusercontent.com/-pkp40ccE7So/AAAAAAAAAAI/AAAAAAAAAU4/Upp1QcV6fHs/s64/photo.jpg","userId":"16137932526864003348"}},"colab":{"base_uri":"https://localhost:8080/","height":654}},"cell_type":"code","source":["plot_loss_acc(history)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-8c37556c587f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-5bbe240a4bba>\u001b[0m in \u001b[0;36mplot_loss_acc\u001b[0;34m(hist)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_loss_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Plot legend and use the best location automatically: loc = 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'history'"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYfAlqQmDL0lNGHxJauJ/Acz2XLpusNoKAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"CK3xqR3hM09r","colab_type":"text"},"cell_type":"markdown","source":["# Create Model 2"]},{"metadata":{"id":"uYhuVnptMnHV","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_batch(dataset, batch_size):\n","    \"\"\" Builds a batch of source and target elements from the dataset.\n","    \n","        Arguments:\n","            dataset: List[db_element] -- A list of dataset elements\n","            batch_size: int -- The size of the batch that should be created\n","        Returns:\n","            batch_input: List[List[int]] -- List of source sequences\n","            batch_target: List[List[int]] -- List of target sequences\n","            batch_target_mask: List[List[int]] -- List of target batch masks\n","    \"\"\"\n","    \n","    indices = list(np.random.randint(0, len(dataset[0]), size=batch_size))\n","    \n","    # Recover what the entries for the batch are\n","    batch_encoder, batch_decoder = np.array([dataset[0][i] for i in indices]), np.array([dataset[1][i] for i in indices])\n","\n","    batch_target = batch_decoder[:, 1:]\n","    \n","    # The target should be the un-shifted numerized input\n","    batch_encoder_input = np.array(batch_encoder)\n","    batch_decoder_input = batch_decoder[:, :-1]\n","\n","    # The target-mask is a 0 or 1 filter to note which tokens are\n","    # padding or not, to give the loss, so the model doesn't get rewarded for\n","    # predicting PAD tokens.\n","    batch_target_mask = batch_target != 0\n","    \n","        \n","    return batch_encoder_input, batch_decoder_input, batch_target, batch_target_mask"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4TZLSoGCH2VR","colab_type":"code","colab":{}},"cell_type":"code","source":["# Using a basic RNN/LSTM for Language modeling\n","class LanguageModel():\n","    def __init__(self, input_length, output_length, vocab_size, rnn_size, batch_size=512, learning_rate=1e-5):\n","        \n","        self.encoder_input = tf.placeholder(tf.int32, shape=[None, input_length])\n","        self.decoder_input = tf.placeholder(tf.int32, shape=[None, output_length])\n","        self.targets = tf.placeholder(tf.int32, shape=[None, output_length])\n","        self.targets_mask = tf.placeholder(tf.int32, shape=[None, output_length])\n","        self.dropout = tf.placeholder_with_default(1.0, shape=())\n","        self.batch_size = batch_size\n","        self.decoder_lengths = tf.placeholder(tf.int32, shape=(self.batch_size))\n","\n","        \n","        embedding = tf.get_variable(\"embedding\", [vocab_size, rnn_size], dtype=tf.float32)\n","        \n","        encoder_emb = tf.nn.embedding_lookup(embedding, self.encoder_input)\n","        decoder_emb = tf.nn.embedding_lookup(embedding, self.decoder_input)\n","        \n","        encoder_cell = tf.nn.rnn_cell.LSTMCell(rnn_size)\n","        dropout_cell = tf.nn.rnn_cell.DropoutWrapper(encoder_cell, input_keep_prob=1.0, output_keep_prob=self.dropout)\n","        _, encoder_state = tf.nn.dynamic_rnn(dropout_cell, encoder_emb, dtype=tf.float32)\n","        \n","        decoder_cell = tf.nn.rnn_cell.LSTMCell(rnn_size)\n","        decoder_cell = tf.nn.rnn_cell.DropoutWrapper(decoder_cell, input_keep_prob=1.0, output_keep_prob=self.dropout)\n","        output_layer = tf.layers.Dense(vocab_size)\n","        \n","        with tf.variable_scope(\"decode\"):\n","          training_helper = tf.contrib.seq2seq.TrainingHelper(decoder_emb, self.decoder_lengths)\n","          training_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, training_helper, encoder_state, output_layer)\n","          training_decoder_output = tf.contrib.seq2seq.dynamic_decode(training_decoder)[0]\n","          \n","        with tf.variable_scope(\"decode\", reuse=True):\n","          start_tokens = tf.tile(tf.constant([start_idx], dtype=tf.int32), [self.batch_size], name='start_tokens')\n","          inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embedding, start_tokens, end_idx)\n","          inference_decoder = tf.contrib.seq2seq.BasicDecoder(decoder_cell, inference_helper, encoder_state, output_layer)\n","          inference_decoder_output = tf.contrib.seq2seq.dynamic_decode(inference_decoder)[0]\n","                  \n","        self.training_logits = tf.identity(training_decoder_output.rnn_output)\n","        self.inference_logits = tf.identity(inference_decoder_output.sample_id)\n","        \n","        print(self.training_logits.shape)\n","        print(inference_decoder_output.rnn_output.shape)\n","        print(self.inference_logits.shape)\n","        print(self.decoder_lengths)\n","                \n","        self.loss = tf.contrib.seq2seq.sequence_loss(self.training_logits, self.targets, weights=tf.cast(self.targets_mask, dtype=tf.float32))\n","        self.global_step = tf.Variable(0, trainable=False)\n","        learning_rate = tf.train.exponential_decay(learning_rate, self.global_step, 100000, 0.96)\n","        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","\n","        self.train_op = optimizer.minimize(self.loss, global_step=self.global_step)\n","        self.saver = tf.train.Saver()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eKAIBufqQU8v","colab_type":"code","colab":{}},"cell_type":"code","source":["train_size = 10000\n","d_train = [encoded_q[:train_size], encoded_a[:train_size]]\n","d_valid = [encoded_q[train_size:], encoded_a[train_size:]]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H1sgjObxQdwB","colab_type":"code","colab":{}},"cell_type":"code","source":["tf.reset_default_graph() # This is so that when you debug, you reset the graph each time you run this, in essence, cleaning the board\n","\n","save_file1 = root_folder+\"models/qa_model\"\n","\n","batch_size = 512\n","epochs = 1\n","\n","iter_per_epoch = 1 # len(d_train[0]) // batch_size\n","total_iterations = iter_per_epoch * epochs\n","print_per_iter = 1\n","eval_per_iter = 1\n","\n","save_per_iter = 19\n","\n","model = LanguageModel(input_length=input_steps, output_length=output_steps - 1, vocab_size=vocab_size, rnn_size=1028, learning_rate=1e-5, batch_size=batch_size)\n","\n","print(\"Total iterations:\", total_iterations)\n","\n","train_losses = []\n","val_losses = []\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    iteration = 1\n","    for epoch in range(1, epochs + 1):\n","        print(\"Epoch:\", epoch)\n","        for _ in range(iter_per_epoch):\n","            batch_encoder_input, batch_decoder_input, batch_target, batch_target_mask = build_batch(d_train, batch_size)\n","            decoder_lens = np.ones((batch_size), dtype=int) * (output_steps - 1)\n","            feed = {model.encoder_input: batch_encoder_input, model.decoder_input: batch_decoder_input, model.targets: batch_target, model.targets_mask: batch_target_mask, model.decoder_lengths: decoder_lens}\n","\n","            step, train_loss, _ = sess.run([model.global_step, model.loss, model.train_op], feed_dict=feed)\n","            train_losses.append(train_loss)\n","\n","            if iteration % print_per_iter == 0:\n","                print(\"Iteration {0} / {1}: Training loss - {2}\".format(iteration, total_iterations, train_loss))\n","            \n","            if iteration % eval_per_iter == 0:\n","                batch_encoder_input, batch_decoder_input, batch_target, batch_target_mask = build_batch(d_valid, batch_size)\n","                feed = {model.encoder_input: batch_encoder_input, model.decoder_input: batch_decoder_input, model.targets: batch_target, model.targets_mask: batch_target_mask, model.decoder_lengths: decoder_lens}\n","                eval_loss = sess.run([model.loss], feed_dict=feed)[0]\n","                print(\"Evaluation loss:\", eval_loss)\n","                val_losses.append(eval_loss)\n","              \n","            if iteration % save_per_iter == 0:\n","              model.saver.save(sess, save_file1)\n","            \n","            iteration += 1\n","    \n","        "],"execution_count":0,"outputs":[]},{"metadata":{"id":"mvuQ8HIeqCpR","colab_type":"code","colab":{}},"cell_type":"code","source":["with tf.Session() as sess:\n","    model.saver.restore(sess, save_file1)\n","    answer_logits = sess.run(model.inference_logits, {model.encoder_input: encoded_q[512:1024]})\n","    print(model.)\n","\n","\n","print(answer_logits)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SclYXYDWqRQc","colab_type":"code","colab":{}},"cell_type":"code","source":["a = answer_logits[0]\n","print(\" \".join(idx2word[i] for i in a))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aXM2QWqY9hYc","colab_type":"code","colab":{}},"cell_type":"code","source":["np.ones((11), dtype=int) * 4"],"execution_count":0,"outputs":[]},{"metadata":{"id":"S6_qnXS8Aygy","colab_type":"text"},"cell_type":"markdown","source":["# Create Model 3"]},{"metadata":{"id":"zkKfuU7NA27V","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"XacNw60eQbZl","colab_type":"text"},"cell_type":"markdown","source":["# Etc"]},{"metadata":{"id":"LfsR2DECo1F0","colab_type":"code","colab":{}},"cell_type":"code","source":["def try_prediction(idx):\n","  question = encoded_q[idx]\n","  question = question.reshape(1, question.shape[0])\n","  to_print = [idx2word[j] for j in question[0]]\n","  to_print = [s for s in to_print if s != 'PAD']\n","  print(\"=======\")\n","  print('Question: ')\n","  print(' '.join(to_print))\n","  answer = np.zeros((1, output_steps))\n","  answer[0, 0] = start_idx\n","  final_ans = []\n","  \n","  for i in range(1, output_steps):\n","    pred = model.predict([question, answer])[0]\n","    pred = np.argmax(pred[i][:])\n","    if pred == 0:\n","      break\n","    answer[0, i] = pred\n","    final_ans.append(idx2word[pred])\n","    \n","  print(\"Answer: \")\n","  print(\" \".join(final_ans))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BSss2_URXzhz","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import load_model\n","model = load_model(root_folder + 'models/keras_model.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-MfEZS32arQB","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_prediction(idx, file):\n","  question = encoded_q[idx]\n","  question = question.reshape(1, question.shape[0])\n","  to_print = [idx2word[j] for j in question[0]]\n","  to_print = [s for s in to_print if s != 'PAD']\n","\n","  print(' '.join(to_print), file = file)\n","  answer = np.zeros((1, output_steps))\n","  answer[0, 0] = start_idx\n","  final_ans = []\n","  \n","  for i in range(1, output_steps):\n","    pred = model.predict([question, answer])[0]\n","    pred = np.argmax(pred[i][:])\n","    if pred == 0:\n","      break\n","    answer[0, i] = pred\n","    final_ans.append(idx2word[pred])\n","    \n","  print(\" \".join(final_ans), file = file)\n","  print(\"\", file = file)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YfyJFiZLaB-6","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(root_folder + \"encoder_decoder_output_jokes.txt\", \"w\") as text_file:\n","  for i in range(500):\n","    make_prediction(i, text_file)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qfAqNqcvo5SU","colab_type":"code","outputId":"bc146da1-2b64-4480-e6ff-9ab4ee88dff2","executionInfo":{"status":"ok","timestamp":1555709464626,"user_tz":420,"elapsed":8318,"user":{"displayName":"SHUN LIN","photoUrl":"https://lh4.googleusercontent.com/-pkp40ccE7So/AAAAAAAAAAI/AAAAAAAAAU4/Upp1QcV6fHs/s64/photo.jpg","userId":"16137932526864003348"}},"colab":{"base_uri":"https://localhost:8080/","height":462}},"cell_type":"code","source":["for i in range(150, 155):\n","  try_prediction(i)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["=======\n","Question: \n","what do you call two gay irishmen\n","Answer: \n","blindly glazing glazing iphotobucketcom centerfold arabias heavily sacrifice resuscitation returns cowpats resuscitation smell convincing population honeymoon underneath pcmasterrace jetpack jellybeans wellapparently wellapparently wellapparently brewing tel watshttp universes dikes\n","=======\n","Question: \n","why do elephants have feet\n","Answer: \n","paramedics mock sauron thsi hassel fired pooper elliott shayamalan thirties guyshttp ninjaedit inviting fruitcake outrun neutral unconstipated arrr pitcher mumbo remove unfaithful whaaat scooter newsand favored curium canvas\n","=======\n","Question: \n","when are they going to drug test the audience of the price is right\n","Answer: \n","losers policy wallaby sculptures duhh shouldve hooking untill quickie investment guinness pffffffhehewheheheheheh plaice plumbum nonindustrious cheerios meatrimony fiance jester drivethru unexp rated newd ehh pews necessary cabinet shittyjoke\n","=======\n","Question: \n","how to get a jewish girls number\n","Answer: \n","prix hour footrace footrace lauren dissimilarities skulls shilled gwen wreckeramp wreckeramp returned biased xenu addition donator completed lbs fan fan methodist methodist redditers moohamad mold sighing realises goo\n","=======\n","Question: \n","why doesnt hitler go ski\n","Answer: \n","outjured ow hdd hdd metro victories mewell toads whispering rocknroll mornings birthing conceited hp bea blonic cp quartered sunscreen eileen statesponsored moving appeals bombastic accuse muscles frustrating foursome\n"],"name":"stdout"}]},{"metadata":{"id":"BJueHvxGgMgc","colab_type":"code","colab":{}},"cell_type":"code","source":["def try_prediction2(question):\n","  question = encoded_q[idx]\n","  question = question.reshape(1, question.shape[0])\n","  print([idx2word[j] for j in question[0]])\n","  answer = np.zeros((1, output_steps))\n","  answer[0, 0] = start_idx\n","  final_ans = []\n","  \n","  for i in range(1, output_steps):\n","    pred = model.predict([question, answer])[0]\n","    pred = np.argmax(pred[i][:])\n","    if pred == 0:\n","      break\n","    answer[0, i] = pred\n","    final_ans.append(idx2word[pred])\n","  \n","  return \" \".join(final_ans)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qt5-gQax70qz","colab_type":"code","outputId":"6784153a-d0ca-4be0-980b-16c39df1136c","executionInfo":{"status":"ok","timestamp":1554177815201,"user_tz":420,"elapsed":468,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"cell_type":"code","source":["question = encoded_q[1332]\n","answer = np.zeros(output_steps)\n","answer[0] = start_idx\n","x=model.predict([question.reshape(1, question.shape[0]), answer.reshape(1, answer.shape[0])])\n","x=x[0,:,:]\n","x"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.5944084e-06, 1.9723384e-06, 7.2512470e-02, ..., 1.9946933e-06,\n","        1.9792726e-06, 2.1494882e-06],\n","       [1.7733514e-06, 2.1303283e-06, 2.7423376e-01, ..., 2.2033059e-06,\n","        2.1994344e-06, 2.2096651e-06],\n","       [9.1821011e-07, 1.0012359e-06, 7.1588421e-01, ..., 1.0198935e-06,\n","        1.0360463e-06, 1.0040509e-06]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"NI3DRPqpBQHB","colab_type":"code","colab":{}},"cell_type":"code","source":["idx = 12\n","batch_size = 1\n","question = train_q[idx:idx+batch_size]\n","target = train_a[idx:idx+batch_size]\n","\n","answer = np.zeros(target.shape)\n","answer[0] = start_idx\n","\n","target = np.hstack((target[:, 1:], np.zeros((batch_size, 1))))\n","mask = np.expand_dims(target != 0, axis=2)\n","target = tf.keras.utils.to_categorical(target, num_classes=vocab_size)\n","#decoder_output = decoder_output.reshape(self.batch_size, self.output_steps, self.vocab_size)\n","target = target * mask\n","\n","x=model.evaluate([question, answer], target, batch_size=batch_size)\n","x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HKkaF9_fBelH","colab_type":"code","outputId":"91c4cab9-413f-486c-abda-5dbe45444cba","executionInfo":{"status":"ok","timestamp":1554177831090,"user_tz":420,"elapsed":427,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":251}},"cell_type":"code","source":["time_distr.get_weights()[0]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.03242446, -0.03689044,  0.02070518, ..., -0.02664001,\n","        -0.02547399, -0.04266471],\n","       [ 0.01969255,  0.0043085 ,  0.02838571, ...,  0.00485123,\n","         0.00916836,  0.00837918],\n","       [-0.01861973, -0.02951997,  0.0206966 , ..., -0.02430052,\n","        -0.01736492, -0.0136068 ],\n","       ...,\n","       [-0.03084927, -0.03844005,  0.01711964, ..., -0.01318076,\n","        -0.03721153, -0.01690714],\n","       [-0.00906306, -0.01056273,  0.01533686, ..., -0.01586072,\n","        -0.04339187, -0.01238717],\n","       [-0.02492933, -0.03824919,  0.01621732, ..., -0.00960355,\n","        -0.01371659, -0.03072176]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":48}]},{"metadata":{"id":"oBhEFewyCluv","colab_type":"code","outputId":"9285d47e-addf-42b9-cbbb-ad03bc26f9d4","executionInfo":{"status":"ok","timestamp":1554067121087,"user_tz":420,"elapsed":608,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["K.clear_session()\n","\n","embed_dim = 128\n","latent_dim = 512\n","\n","encoder_inputs = Input(shape=(input_steps,))\n","decoder_inputs = Input(shape=(output_steps,))\n","embedding = Embedding(vocab_size, embed_dim)\n","enc_embed = embedding(encoder_inputs)\n","dec_embed = embedding(decoder_inputs)\n","\n","encoder_LSTM = LSTM(latent_dim, dropout=0.2, recurrent_dropout=0.2, return_state=True)\n","_, encoder_h, encoder_c = encoder_LSTM(enc_embed)\n","\n","\n","decoder_LSTM = LSTM(latent_dim, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)\n","decoder_outputs = decoder_LSTM(dec_embed, initial_state=[encoder_h, encoder_c])\n","\n","time_distr = TimeDistributed(Dense(vocab_size, activation='softmax'))(decoder_outputs)\n","outputs = Lambda(crop_outputs, output_shape=(output_steps, vocab_size))([outputs, decoder_inputs])\n","model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=outputs)\n","model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n","print(model.summary())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[4.720688195902767e-08, 0.6039999723434448]"]},"metadata":{"tags":[]},"execution_count":91}]},{"metadata":{"id":"TGMEf7fRCuMm","colab_type":"code","outputId":"6b05b017-3dff-4bc8-c4aa-f7a5a545ece8","executionInfo":{"status":"ok","timestamp":1554015971558,"user_tz":420,"elapsed":978,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["K.cast(K.not_equal(train_a, 0), dtype=K.floatx())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'Cast:0' shape=(70297, 36) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":171}]},{"metadata":{"id":"HsU1dmeWRRO9","colab_type":"code","colab":{}},"cell_type":"code","source":["a = np.hstack((train_a[:1][:, 1:], np.zeros((1, 1))))\n","mask = a != 0\n","a = tf.keras.utils.to_categorical(a, num_classes=vocab_size)\n","#a = a.reshape(1, output_steps, vocab_size)\n","\n","a = a * np.expand_dims(mask, axis=2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xPZi34hNVsLf","colab_type":"code","outputId":"823c4b2d-8dbb-4290-9840-3bd8c8b4e843","executionInfo":{"status":"ok","timestamp":1554062470424,"user_tz":420,"elapsed":657,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["mask.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1, 36)"]},"metadata":{"tags":[]},"execution_count":54}]},{"metadata":{"id":"vg9BF7aLRiy0","colab_type":"code","outputId":"ae3a8621-cc0b-46eb-d152-ab6c867a18e8","executionInfo":{"status":"ok","timestamp":1554062523052,"user_tz":420,"elapsed":580,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        ...,\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.],\n","        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":57}]},{"metadata":{"id":"y2jXuoR5SJ_t","colab_type":"code","outputId":"ef24e9d5-4c8b-4d9e-cc9f-86b74911529c","executionInfo":{"status":"ok","timestamp":1554062538205,"user_tz":420,"elapsed":394,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"cell_type":"code","source":["train_a[:1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[    1,    20,  2463,   283,     9,     2,   870,   581, 16592,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0]],\n","      dtype=int32)"]},"metadata":{"tags":[]},"execution_count":59}]},{"metadata":{"id":"kEsX7frLSMys","colab_type":"code","outputId":"184c9777-c514-4c36-839f-ac02ffb36e76","executionInfo":{"status":"ok","timestamp":1554062561759,"user_tz":420,"elapsed":583,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["np.sum(a[0, 7, :])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.0"]},"metadata":{"tags":[]},"execution_count":63}]},{"metadata":{"id":"rjFs9cOVSODD","colab_type":"code","outputId":"38937dc7-a345-43e0-c688-b3f5a56aae89","executionInfo":{"status":"ok","timestamp":1554061606971,"user_tz":420,"elapsed":681,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44467"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"yRkuucpNSj0v","colab_type":"code","outputId":"f517f99e-75c1-47d5-b921-a6a600b3b8f0","executionInfo":{"status":"ok","timestamp":1554061617855,"user_tz":420,"elapsed":421,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["len(idx2word)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44467"]},"metadata":{"tags":[]},"execution_count":31}]},{"metadata":{"id":"78-y7zSkSmiz","colab_type":"code","outputId":"11a53d92-9e13-41df-8d02-e559be263614","executionInfo":{"status":"error","timestamp":1554061623082,"user_tz":420,"elapsed":441,"user":{"displayName":"Jerry Chen","photoUrl":"","userId":"09742178804226077447"}},"colab":{"base_uri":"https://localhost:8080/","height":169}},"cell_type":"code","source":["idx2word[0]"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-6f424559a662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyError\u001b[0m: 0"]}]},{"metadata":{"id":"c30m1BBDSn0M","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}